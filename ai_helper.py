# --- filename: ai_helper.py ---
import streamlit as st
from openai import OpenAI

# é…ç½®ä½ çš„ API
API_KEY = "sk-vVIGbUylII5Kg9rZwGLZMzzubt778St90r66gGtTXTUs4shK" 
BASE_URL = "https://api.openai-proxy.org/v1"
MODEL_NAME = "gpt-3.5-turbo" 

def init_ai_session():
    """åˆå§‹åŒ– AI å®¢æˆ·ç«¯å’Œå†å²è®°å½•"""
    if "ai_client" not in st.session_state:
        try:
            st.session_state.ai_client = OpenAI(
                api_key=API_KEY, 
                base_url=BASE_URL
            )
        except Exception as e:
            st.error(f"AI å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            st.session_state.ai_client = None

    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç”µå­ç”µè·¯åŠ©æ•™ã€‚"}
        ]

def render_floating_assistant():
    """æ¸²æŸ“å¹³æ¿ä¼˜åŒ–çš„æ‚¬æµ®å¯¹è¯æ¡† (CSS å¢å¼ºç‰ˆ)"""
    init_ai_session()
    
    st.markdown("""
    <style>
    /* å‘¼å¸åŠ¨ç”» */
    @keyframes pulse-purple {
        0% { box-shadow: 0 0 0 0 rgba(102, 126, 234, 0.7); }
        70% { box-shadow: 0 0 0 20px rgba(102, 126, 234, 0); }
        100% { box-shadow: 0 0 0 0 rgba(102, 126, 234, 0); }
    }

    /* 1. å®¹å™¨å®šä½ï¼šå¼ºåˆ¶å³ä¸Šè§’ */
    /* æ³¨æ„ï¼šè¿™é‡Œæ”¹ç”¨äº†æ›´å®½æ¾çš„é€‰æ‹©å™¨ï¼Œåªè¦å«æœ‰ stPopover å°±å¯ä»¥ */
    [data-testid="stPopover"] {
        position: fixed !important;
        top: 30px !important;    /* è·ç¦»é¡¶éƒ¨è°ƒå°ä¸€ç‚¹ï¼Œé˜²é®æŒ¡ */
        right: 30px !important;  /* è·ç¦»å³ä¾§ */
        left: auto !important;   /* å¿…é¡»å¼ºåˆ¶å–æ¶ˆå·¦ä¾§å®šä½ */
        bottom: auto !important;
        z-index: 9999999 !important; /* å±‚çº§æ‹‰æ»¡ */
        transform: none !important;
        width: auto !important;
        height: auto !important;
    }
    
    /* 2. æŒ‰é’®æ ·å¼ï¼šå¤§å·ç´«è‰²åœ†å½¢ */
    /* ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šæŠŠ "> div > button" æ”¹æˆäº† "button"ï¼ŒåŒ¹é…æ›´å¼º */
    [data-testid="stPopover"] button {
        width: 80px !important;
        height: 80px !important;
        border-radius: 50% !important;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        border: 3px solid white !important; /* åŠ ç²—ç™½è¾¹ï¼Œæ›´æ˜æ˜¾ */
        box-shadow: 0 10px 25px rgba(102, 126, 234, 0.4) !important;
        
        animation: pulse-purple 2s infinite;
        transition: transform 0.2s ease;
        
        display: flex !important;
        align-items: center !important;
        justify-content: center !important;
        padding: 0 !important;
        margin: 0 !important;
    }
    
    /* 3. å›¾æ ‡æ ·å¼ */
    [data-testid="stPopover"] button div,
    [data-testid="stPopover"] button span,
    [data-testid="stPopover"] button p {
        font-size: 40px !important;
        color: white !important;
        line-height: 1 !important;
        margin: 0 !important;
        padding: 0 !important;
    }
    
    /* 4. äº¤äº’æ•ˆæœ */
    [data-testid="stPopover"] button:active {
        transform: scale(0.9) !important;
        animation: none !important;
        background: #5a67d8 !important;
    }
    
    [data-testid="stPopover"] button:hover {
        transform: scale(1.05) !important;
    }

    /* 5. å±•å¼€åçš„å¯¹è¯æ¡†ç¾åŒ– */
    [data-testid="stPopoverBody"] {
        width: 400px !important;
        max-width: 90vw !important;
        border-radius: 20px !important;
        border: 1px solid #eee !important;
        box-shadow: 0 20px 60px rgba(0,0,0,0.15) !important;
        top: 120px !important; /* è°ƒæ•´å±•å¼€æ¡†çš„ä½ç½®ï¼Œä¸è¦ç›–ä½æŒ‰é’® */
        right: 30px !important;
    }
    </style>
    """, unsafe_allow_html=True)

    with st.popover("ğŸ¤–", use_container_width=False):
        st.markdown("### ğŸ’¬ åŠ©æ•™å°ç”µ")
        
        msg_container = st.container(height=400)
        with msg_container:
            for msg in st.session_state.messages:
                if msg["role"] != "system":
                    with st.chat_message(msg["role"]):
                        st.markdown(msg["content"])

        if prompt := st.chat_input("æˆ‘çš„ç”µè·¯å“ªé‡Œæœ‰é—®é¢˜ï¼Ÿ"):
            log_context = st.session_state.get("recognition_log", "ï¼ˆå­¦ç”Ÿå°šæœªä¸Šä¼ å›¾ç‰‡ï¼‰")
            dynamic_system_prompt = f"""
            ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç”µå­ç”µè·¯åŠ©æ•™ã€‚
            ã€å½“å‰æ£€æµ‹çŠ¶æ€ã€‘ï¼š{log_context}
            è¯·ä¼˜å…ˆè§£ç­”æ¥çº¿é”™è¯¯ã€‚
            """
            
            if len(st.session_state.messages) > 0 and st.session_state.messages[0]["role"] == "system":
                st.session_state.messages[0]["content"] = dynamic_system_prompt

            with msg_container:
                st.chat_message("user").markdown(prompt)
            st.session_state.messages.append({"role": "user", "content": prompt})

            if st.session_state.ai_client:
                with msg_container:
                    with st.chat_message("assistant"):
                        stream_box = st.empty()
                        full_response = ""
                        try:
                            stream = st.session_state.ai_client.chat.completions.create(
                                model=MODEL_NAME,
                                messages=st.session_state.messages,
                                stream=True
                            )
                            for chunk in stream:
                                if chunk.choices and len(chunk.choices) > 0:
                                    delta = chunk.choices[0].delta
                                    if delta.content:
                                        full_response += delta.content
                                        stream_box.markdown(full_response + "â–Œ")
                            stream_box.markdown(full_response)
                            st.session_state.messages.append({"role": "assistant", "content": full_response})
                        except Exception as e:
                            st.error(f"AI å“åº”ä¸­æ–­: {str(e)}")
            else:
                st.error("AI å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
