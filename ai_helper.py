# --- filename: ai_helper.py ---
import streamlit as st
from openai import OpenAI

# é…ç½®ä½ çš„ API
API_KEY = "sk-vVIGbUylII5Kg9rZwGLZMzzubt778St90r66gGtTXTUs4shK" 
BASE_URL = "https://api.openai-proxy.org/v1"
MODEL_NAME = "gpt-4o" 

def init_ai_session():
    """åˆå§‹åŒ– AI å®¢æˆ·ç«¯å’Œå†å²è®°å½•"""
    if "ai_client" not in st.session_state:
        try:
            st.session_state.ai_client = OpenAI(
                api_key=API_KEY, 
                base_url=BASE_URL
            )
        except Exception as e:
            st.error(f"AI å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            st.session_state.ai_client = None

    if "messages" not in st.session_state:
        # åˆå§‹åŒ– system promptï¼Œç¨åæˆ‘ä»¬ä¼šåŠ¨æ€æ›´æ–°å®ƒ
        st.session_state.messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç”µå­ç”µè·¯åŠ©æ•™ã€‚"}
        ]

def render_floating_assistant():
    """æ¸²æŸ“åº•éƒ¨é•¿æ¡å½¢æ‚¬æµ®å¯¹è¯æ¡†"""
    init_ai_session()
    
    # CSS æ ·å¼ (ä¿æŒä¸å˜)
    st.markdown("""
    <style>
    [data-testid="stPopover"] {
        position: fixed; bottom: 40px; right: 40px; z-index: 9999;
    }
    [data-testid="stPopover"] > div > button {
        width: 260px; height: 55px; border-radius: 30px; 
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
        color: white; border: none; box-shadow: 0 10px 20px rgba(0,0,0,0.2);
        font-size: 16px; font-weight: bold; transition: all 0.3s ease;
        display: flex; align-items: center; justify-content: center;
    }
    [data-testid="stPopover"] > div > button::after {
        content: "ğŸ¤– æœ‰é—®é¢˜ï¼Ÿé—®é—® AI åŠ©æ•™"; margin-left: 8px;
    }
    [data-testid="stPopover"] > div > button:hover {
        transform: translateY(-5px); box-shadow: 0 15px 25px rgba(0,0,0,0.3);
    }
    </style>
    """, unsafe_allow_html=True)

    with st.popover("ğŸ’¬", use_container_width=False):
        st.markdown("### ğŸ¤– ç”µè·¯ç™¾äº‹é€š")
        
        msg_container = st.container(height=400)
        with msg_container:
            for msg in st.session_state.messages:
                if msg["role"] != "system":
                    with st.chat_message(msg["role"]):
                        st.markdown(msg["content"])

        if prompt := st.chat_input("æˆ‘çš„ç”µè·¯å“ªé‡Œæœ‰é—®é¢˜ï¼Ÿ"):
            # ================= ğŸ”¥ æ ¸å¿ƒä¼˜åŒ–ï¼šåŠ¨æ€æ³¨å…¥ä¸Šä¸‹æ–‡ =================
            # 1. è·å–æœ€æ–°çš„åˆ¤å·æ—¥å¿—
            log_context = st.session_state.get("recognition_log", "ï¼ˆå­¦ç”Ÿå°šæœªä¸Šä¼ å›¾ç‰‡æˆ–è¿›è¡Œè¯†åˆ«ï¼‰")
            
            # 2. æ„é€ æ›´åŠ æ™ºèƒ½çš„ System Prompt
            dynamic_system_prompt = f"""
            ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç”µå­ç”µè·¯åŠ©æ•™ï¼Œè´Ÿè´£æŒ‡å¯¼å­¦ç”Ÿè¿æ¥ CD4026 è®¡æ•°å™¨ç”µè·¯ã€‚
            
            ã€å½“å‰å­¦ç”Ÿçš„ç”µè·¯æ¿çŠ¶æ€ï¼ˆç”±è§†è§‰ç®—æ³•æ£€æµ‹ï¼‰ã€‘
            {log_context}
            
            è¯·æ ¹æ®æ£€æµ‹åˆ°çš„é”™è¯¯ï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œä¼˜å…ˆè§£ç­”å­¦ç”Ÿçš„æ¥çº¿é—®é¢˜ã€‚
            å¦‚æœæ£€æµ‹æŠ¥å‘Šå…¨æ˜¯æ­£ç¡®çš„ï¼Œè¯·å¤¸å¥–å­¦ç”Ÿã€‚
            å›ç­”è¦äº²åˆ‡ã€ç®€æ´ï¼Œä¸è¦é•¿ç¯‡å¤§è®ºã€‚
            """
            
            # 3. æ‚„æ‚„æ›´æ–° system prompt (messages[0])ï¼Œè®© AI çŸ¥é“æœ€æ–°æƒ…å†µ
            if len(st.session_state.messages) > 0 and st.session_state.messages[0]["role"] == "system":
                st.session_state.messages[0]["content"] = dynamic_system_prompt
            # ================= ğŸ”¥ ä¼˜åŒ–ç»“æŸ =================

            with msg_container:
                st.chat_message("user").markdown(prompt)
            st.session_state.messages.append({"role": "user", "content": prompt})

            if st.session_state.ai_client:
                with msg_container:
                    with st.chat_message("assistant"):
                        stream_box = st.empty()
                        full_response = ""
                        try:
                            stream = st.session_state.ai_client.chat.completions.create(
                                model=MODEL_NAME,
                                messages=st.session_state.messages,
                                stream=True
                            )
                            for chunk in stream:
                                if chunk.choices and len(chunk.choices) > 0:
                                    delta = chunk.choices[0].delta
                                    if delta.content:
                                        full_response += delta.content
                                        stream_box.markdown(full_response + "â–Œ")
                            
                            stream_box.markdown(full_response)
                            st.session_state.messages.append({"role": "assistant", "content": full_response})
                        except Exception as e:
                            st.error(f"AI å“åº”ä¸­æ–­: {str(e)}")
            else:
                st.error("AI å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")