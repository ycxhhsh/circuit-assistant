# --- filename: ai_helper.py ---
import streamlit as st
from openai import OpenAI

# é…ç½®ä½ çš„ API
API_KEY = "sk-vVIGbUylII5Kg9rZwGLZMzzubt778St90r66gGtTXTUs4shK" 
BASE_URL = "https://api.openai-proxy.org/v1"
MODEL_NAME = "gpt-4o" 

def init_ai_session():
    """åˆå§‹åŒ– AI å®¢æˆ·ç«¯å’Œå†å²è®°å½•"""
    if "ai_client" not in st.session_state:
        try:
            st.session_state.ai_client = OpenAI(
                api_key=API_KEY, 
                base_url=BASE_URL
            )
        except Exception as e:
            st.error(f"AI å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            st.session_state.ai_client = None

    if "messages" not in st.session_state:
        # è®¾å®šä¸€ä¸ªé™æ€çš„ System Promptï¼ŒåŒ…å«ç”µè·¯çŸ¥è¯†ï¼Œä½†ä¸åŒ…å«å®æ—¶æ£€æµ‹çŠ¶æ€
        system_instruction = """
        ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç”µå­ç”µè·¯åŠ©æ•™ï¼Œæ­£åœ¨æŒ‡å¯¼å­¦ç”Ÿè¿æ¥ CD4026 è®¡æ•°å™¨èŠ¯ç‰‡ã€‚

        ã€å®éªŒèƒŒæ™¯ä¿¡æ¯ã€‘
        ä¸ºäº†é™ä½éš¾åº¦ï¼Œæ•°ç ç®¡å’Œç”µæºçº¿é€šå¸¸å·²é¢„è®¾æ¥å¥½ã€‚
        å­¦ç”Ÿä¸»è¦è´Ÿè´£ä»¥ä¸‹ 4 ä¸ªæ ¸å¿ƒå¼•è„šçš„è¿æ¥ï¼Œæ ‡å‡†æ¥æ³•å¦‚ä¸‹ï¼š
        1. Pin 1 (CLK) -> æ¥æ—¶é’Ÿä¿¡å·
        2. Pin 2 (INH) -> æ¥å¼€å…³æˆ–æ¥åœ° (ä½ç”µå¹³æœ‰æ•ˆ)
        3. Pin 3 (DEI) -> æ¥ VCC (Pin 16) (é«˜ç”µå¹³æœ‰æ•ˆ)
        4. Pin 15 (RST) -> æ¥æ¥åœ° (Pin 8) (å¤ä½ç«¯)

        è¯·æ ¹æ®ä»¥ä¸Šæ ‡å‡†å›ç­”å­¦ç”Ÿçš„æé—®ã€‚å¦‚æœå­¦ç”Ÿé—®â€œæˆ‘è¯¥æ€ä¹ˆæ¥â€ï¼Œè¯·å¼•å¯¼ä»–ä»¬å®Œæˆè¿™å››ä¸ªå¼•è„šçš„è¿æ¥ã€‚
        """
        st.session_state.messages = [
            {"role": "system", "content": system_instruction}
        ]

def render_floating_assistant():
    """æ¸²æŸ“å¹³æ¿ä¼˜åŒ–çš„æ‚¬æµ®å¯¹è¯æ¡†"""
    init_ai_session()
    
    st.markdown("""
    <style>
    /* 1. å®šä½å®¹å™¨ï¼šå³ä¸Šè§’åä¸‹ */
    [data-testid="stPopover"] {
        position: fixed;
        top: 100px;
        right: 30px;
        z-index: 99999;
    }
    
    /* 2. æŒ‰é’®æ ·å¼ï¼šå¤§å·å¹³æ¿è§¦æ§ç‰ˆ */
    [data-testid="stPopover"] > div > button {
        width: 72px;
        height: 72px;
        border-radius: 35px;
        background: #ffffff;
        color: #333;
        border: 1px solid #e0e0e0;
        box-shadow: 0 8px 24px rgba(0,0,0,0.12); 
        transition: transform 0.2s cubic-bezier(0.34, 1.56, 0.64, 1);
        display: flex;
        align-items: center;
        justify-content: center;
        padding: 0;
    }
    
    /* 3. æ”¾å¤§å†…éƒ¨çš„ Emoji å›¾æ ‡ */
    [data-testid="stPopover"] > div > button > div {
        font-size: 36px !important;
    }
    
    /* 4. æŒ‰ä¸‹æ•ˆæœ */
    [data-testid="stPopover"] > div > button:active {
        transform: scale(0.9);
        background-color: #f5f5f5;
    }
    
    /* 5. å±•å¼€åçš„å¯¹è¯æ¡†æ ·å¼ */
    [data-testid="stPopoverBody"] {
        width: 380px !important;
        max-width: 90vw;
        border-radius: 20px !important;
        border: none !important;
        box-shadow: 0 20px 60px rgba(0,0,0,0.15) !important;
    }
    </style>
    """, unsafe_allow_html=True)

    # æŒ‰é’®é‡Œåªæ”¾ä¸€ä¸ªå›¾æ ‡
    with st.popover("ğŸ¤–", use_container_width=False):
        st.markdown("### ğŸ’¬ åŠ©æ•™å°ç”µ")
        
        msg_container = st.container(height=400)
        with msg_container:
            for msg in st.session_state.messages:
                if msg["role"] != "system":
                    with st.chat_message(msg["role"]):
                        st.markdown(msg["content"])

        # æç¤ºè¯­å¯ä»¥æ”¹å¾—é€šç”¨ä¸€ç‚¹
        if prompt := st.chat_input("å…³äºç”µè·¯æœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿ"):
            
            # --- å˜åŠ¨å¤„ï¼šç§»é™¤äº†ä¹‹å‰çš„ log_context è·å–å’Œ system prompt åŠ¨æ€æ›´æ–°é€»è¾‘ ---
            
            with msg_container:
                st.chat_message("user").markdown(prompt)
            st.session_state.messages.append({"role": "user", "content": prompt})

            if st.session_state.ai_client:
                with msg_container:
                    with st.chat_message("assistant"):
                        stream_box = st.empty()
                        full_response = ""
                        try:
                            stream = st.session_state.ai_client.chat.completions.create(
                                model=MODEL_NAME,
                                messages=st.session_state.messages,
                                stream=True
                            )
                            for chunk in stream:
                                if chunk.choices and len(chunk.choices) > 0:
                                    delta = chunk.choices[0].delta
                                    if delta.content:
                                        full_response += delta.content
                                        stream_box.markdown(full_response + "â–Œ")
                            
                            stream_box.markdown(full_response)
                            st.session_state.messages.append({"role": "assistant", "content": full_response})
                        except Exception as e:
                            st.error(f"AI å“åº”ä¸­æ–­: {str(e)}")
            else:
                st.error("AI å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
