# --- filename: ai_helper.py ---
import streamlit as st
from openai import OpenAI

# é…ç½®ä½ çš„ API
API_KEY = "sk-vVIGbUylII5Kg9rZwGLZMzzubt778St90r66gGtTXTUs4shK" 
BASE_URL = "https://api.openai-proxy.org/v1"
MODEL_NAME = "gpt-4o" 

def init_ai_session():
    """åˆå§‹åŒ– AI å®¢æˆ·ç«¯å’Œå†å²è®°å½•"""
    if "ai_client" not in st.session_state:
        try:
            st.session_state.ai_client = OpenAI(
                api_key=API_KEY, 
                base_url=BASE_URL
            )
        except Exception as e:
            st.error(f"AI å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            st.session_state.ai_client = None

    if "messages" not in st.session_state:
        # --- ğŸ”¥ ä¿®æ”¹éƒ¨åˆ†ï¼šæ›´è‡ªç„¶çš„äººè®¾ ---
        system_instruction = """
        ä½ æ˜¯ä¸€ä½å‹å–„ã€ä¸“ä¸šçš„ç”µå­ç”µè·¯åŠ©æ•™ï¼ˆåå­—å«â€œåŠ©æ•™å°ç”µâ€ï¼‰ã€‚
        
        ä½ çš„ä¸»è¦ä»»åŠ¡æ˜¯è§£ç­”å­¦ç”Ÿå…³äºç”µè·¯ã€ç”µå­å…ƒå™¨ä»¶ï¼ˆç‰¹åˆ«æ˜¯ CD4026 èŠ¯ç‰‡ï¼‰ä»¥åŠå®éªŒè°ƒè¯•çš„é—®é¢˜ã€‚
        
        ã€è¡Œä¸ºå‡†åˆ™ã€‘
        1. è¯·åƒä¸€ä½è€å¿ƒçš„å­¦é•¿æˆ–è€å¸ˆä¸€æ ·æ­£å¸¸äº¤æµï¼Œä¸è¦æœºæ¢°åœ°é‡å¤è§„åˆ™ã€‚
        2. åªæœ‰å½“å­¦ç”Ÿæ˜ç¡®è¯¢é—®â€œæ€ä¹ˆæ¥çº¿â€ã€â€œå¼•è„šå®šä¹‰â€æˆ–â€œç”µè·¯è¿é”™äº†â€æ—¶ï¼Œä½ æ‰éœ€è¦å¼•ç”¨å…·ä½“çš„ CD4026 å¼•è„šçŸ¥è¯†ï¼ˆå¦‚ Pin 1 CLK, Pin 2 INH, Pin 15 RST ç­‰ï¼‰ã€‚
        3. å›ç­”è¦ç®€æ´æ˜äº†ï¼Œé¼“åŠ±å­¦ç”Ÿè‡ªå·±åŠ¨æ‰‹å°è¯•ã€‚
        """
        st.session_state.messages = [
            {"role": "system", "content": system_instruction}
        ]

def render_floating_assistant():
    """æ¸²æŸ“å¹³æ¿ä¼˜åŒ–çš„æ‚¬æµ®å¯¹è¯æ¡† - æœ€ç»ˆä¿®å¤ç‰ˆ"""
    init_ai_session()
    
    st.markdown("""
    <style>
    /* --- 1. æŒ‰é’®å®¹å™¨ï¼šå¼ºåˆ¶å›ºå®šåœ¨å³ä¸Šè§’ --- */
    [data-testid="stPopover"] {
        position: fixed !important;
        top: 80px !important;       /* é¿å¼€é¡¶éƒ¨ Header */
        right: 40px !important;     /* é å³ */
        left: auto !important;      /* ç¦ç”¨å·¦ä¾§å®šä½ */
        bottom: auto !important;
        z-index: 9999999 !important; /* æœ€é«˜å±‚çº§ï¼Œé˜²æ­¢è¢«ä¾§è¾¹æ é®æŒ¡ */
        width: auto !important;
    }

    /* --- 2. æŒ‰é’®æœ¬ä½“æ ·å¼ --- */
    [data-testid="stPopover"] > div > button {
        width: 64px !important;
        height: 64px !important;
        border-radius: 50% !important;
        background: #ffffff !important;
        color: #333 !important;
        border: 1px solid #ddd !important;
        box-shadow: 0 4px 16px rgba(0,0,0,0.2) !important;
        font-size: 32px !important;
        padding: 0 !important;
        display: flex !important;
        align-items: center !important;
        justify-content: center !important;
    }
    
    /* æŒ‰ä¸‹åé¦ˆ */
    [data-testid="stPopover"] > div > button:active {
        transform: scale(0.95);
        background-color: #f0f0f0 !important;
    }

    /* --- 3. å¼¹å‡ºå¯¹è¯æ¡†ï¼šå¼ºåˆ¶å›ºå®šä½ç½®ï¼Œé˜²æ­¢æˆªæ–­ --- */
    [data-testid="stPopoverBody"] {
        position: fixed !important;
        top: 154px !important;      /* æŒ‰é’®åº•éƒ¨ä¸‹æ–¹ (80+64+10) */
        right: 40px !important;     /* ä¸æŒ‰é’®å³å¯¹é½ */
        left: auto !important;
        transform: none !important; /* å…³é”®ï¼šç¦ç”¨ Streamlit è‡ªåŠ¨è®¡ç®—ä½ç½® */
        
        width: 380px !important;
        max-width: 85vw !important;
        max-height: 600px !important;
        
        border-radius: 12px !important;
        box-shadow: 0 10px 40px rgba(0,0,0,0.2) !important;
        border: 1px solid #eee !important;
        z-index: 9999999 !important;
    }
    </style>
    """, unsafe_allow_html=True)

    # æŒ‰é’®å†…å®¹
    with st.popover("âš¡", use_container_width=False):
        st.markdown("### ğŸ’¬ åŠ©æ•™å°ç”µ")
        
        # èŠå¤©è®°å½•å®¹å™¨
        msg_container = st.container(height=350)
        with msg_container:
            for msg in st.session_state.messages:
                if msg["role"] != "system":
                    with st.chat_message(msg["role"]):
                        st.markdown(msg["content"])

        # è¾“å…¥æ¡†
        if prompt := st.chat_input("åŒå­¦ï¼Œæœ‰ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ"):
            with msg_container:
                st.chat_message("user").markdown(prompt)
            st.session_state.messages.append({"role": "user", "content": prompt})

            if st.session_state.ai_client:
                with msg_container:
                    with st.chat_message("assistant"):
                        stream_box = st.empty()
                        full_response = ""
                        try:
                            stream = st.session_state.ai_client.chat.completions.create(
                                model=MODEL_NAME,
                                messages=st.session_state.messages,
                                stream=True
                            )
                            for chunk in stream:
                                if chunk.choices:
                                    delta = chunk.choices[0].delta
                                    if delta.content:
                                        full_response += delta.content
                                        stream_box.markdown(full_response + "â–Œ")
                            
                            stream_box.markdown(full_response)
                            st.session_state.messages.append({"role": "assistant", "content": full_response})
                        except Exception as e:
                            st.error(f"Error: {str(e)}")
            else:
                st.error("AI å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
