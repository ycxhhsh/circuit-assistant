# --- filename: ai_helper.py ---
import streamlit as st
from openai import OpenAI

# é…ç½®ä½ çš„ API
API_KEY = "sk-vVIGbUylII5Kg9rZwGLZMzzubt778St90r66gGtTXTUs4shK" 
BASE_URL = "https://api.openai-proxy.org/v1"
MODEL_NAME = "gpt-3.5-turbo" 

def init_ai_session():
    """åˆå§‹åŒ– AI å®¢æˆ·ç«¯å’Œå†å²è®°å½•"""
    if "ai_client" not in st.session_state:
        try:
            st.session_state.ai_client = OpenAI(
                api_key=API_KEY, 
                base_url=BASE_URL
            )
        except Exception as e:
            st.error(f"AI å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            st.session_state.ai_client = None

    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç”µå­ç”µè·¯åŠ©æ•™ã€‚"}
        ]

def render_floating_assistant():
    """æ¸²æŸ“å¹³æ¿ä¼˜åŒ–çš„æ‚¬æµ®å¯¹è¯æ¡† (å¼ºåˆ¶å³ä¸Šè§’ç‰ˆ)"""
    init_ai_session()
    
    st.markdown("""
    <style>
    /* å®šä¹‰å‘¼å¸åŠ¨ç”»ï¼šè®©æŒ‰é’®æœ‰â€œæ´»ç€â€çš„æ„Ÿè§‰ */
    @keyframes pulse-purple {
        0% { box-shadow: 0 0 0 0 rgba(102, 126, 234, 0.7); }
        70% { box-shadow: 0 0 0 20px rgba(102, 126, 234, 0); }
        100% { box-shadow: 0 0 0 0 rgba(102, 126, 234, 0); }
    }

    /* 1. å®šä½å®¹å™¨ï¼šä½¿ç”¨ !important å¼ºåˆ¶å›ºå®šåœ¨å³ä¸Šè§’ */
    [data-testid="stPopover"] {
        position: fixed !important;
        top: 80px !important;    /* è·ç¦»é¡¶éƒ¨ */
        right: 40px !important;  /* è·ç¦»å³ä¾§ */
        left: auto !important;   /* å¼ºåˆ¶å–æ¶ˆå·¦ä¾§å®šä½ */
        z-index: 999999 !important;
        transform: none !important; /* é˜²æ­¢çˆ¶å®¹å™¨å¹²æ‰° */
    }
    
    /* 2. æŒ‰é’®æ ·å¼ï¼šå¼ºåˆ¶å˜å¤§ (80px) */
    [data-testid="stPopover"] > div > button {
        width: 80px !important;       /* å¼ºåˆ¶å®½åº¦ */
        height: 80px !important;      /* å¼ºåˆ¶é«˜åº¦ */
        border-radius: 50% !important; /* å¼ºåˆ¶åœ†å½¢ */
        
        /* æ¸å˜ç´«èƒŒæ™¯ */
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        border: 2px solid white !important;
        
        /* å‘¼å¸åŠ¨ç”» */
        animation: pulse-purple 2s infinite;
        
        transition: transform 0.2s cubic-bezier(0.34, 1.56, 0.64, 1);
        display: flex;
        align-items: center;
        justify-content: center;
        padding: 0 !important;
        margin: 0 !important;
    }
    
    /* 3. å›¾æ ‡æ ·å¼ï¼šå¼ºåˆ¶å˜å¤§ */
    [data-testid="stPopover"] > div > button > div,
    [data-testid="stPopover"] > div > button > span {
        font-size: 40px !important; /* å›¾æ ‡æå¤§ */
        color: white !important;
        line-height: 1 !important;
    }
    
    /* 4. æŒ‰ä¸‹åé¦ˆ */
    [data-testid="stPopover"] > div > button:active {
        transform: scale(0.9) !important;
        animation: none !important;
    }
    
    /* 5. å±•å¼€åçš„å¯¹è¯æ¡†ç¾åŒ– */
    [data-testid="stPopoverBody"] {
        width: 400px !important;
        max-width: 90vw !important;
        border-radius: 24px !important;
        border: none !important;
        box-shadow: 0 20px 60px rgba(0,0,0,0.2) !important;
    }
    </style>
    """, unsafe_allow_html=True)

    # æŒ‰é’®å†…å®¹ (åªæ”¾å›¾æ ‡)
    with st.popover("ğŸ¤–", use_container_width=False):
        st.markdown("### ğŸ’¬ åŠ©æ•™å°ç”µ")
        
        # æ¶ˆæ¯å®¹å™¨
        msg_container = st.container(height=400)
        with msg_container:
            for msg in st.session_state.messages:
                if msg["role"] != "system":
                    with st.chat_message(msg["role"]):
                        st.markdown(msg["content"])

        # è¾“å…¥æ¡†
        if prompt := st.chat_input("æˆ‘çš„ç”µè·¯å“ªé‡Œæœ‰é—®é¢˜ï¼Ÿ"):
            # è·å–æœ€æ–°åˆ¤å·æ—¥å¿—
            log_context = st.session_state.get("recognition_log", "ï¼ˆå­¦ç”Ÿå°šæœªä¸Šä¼ å›¾ç‰‡æˆ–è¿›è¡Œè¯†åˆ«ï¼‰")
            dynamic_system_prompt = f"""
            ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç”µå­ç”µè·¯åŠ©æ•™ã€‚
            ã€å½“å‰æ£€æµ‹çŠ¶æ€ã€‘ï¼š{log_context}
            è¯·ä¼˜å…ˆè§£ç­”æ¥çº¿é”™è¯¯ã€‚
            """
            
            # æ›´æ–° system prompt
            if len(st.session_state.messages) > 0 and st.session_state.messages[0]["role"] == "system":
                st.session_state.messages[0]["content"] = dynamic_system_prompt

            with msg_container:
                st.chat_message("user").markdown(prompt)
            st.session_state.messages.append({"role": "user", "content": prompt})

            if st.session_state.ai_client:
                with msg_container:
                    with st.chat_message("assistant"):
                        stream_box = st.empty()
                        full_response = ""
                        try:
                            stream = st.session_state.ai_client.chat.completions.create(
                                model=MODEL_NAME,
                                messages=st.session_state.messages,
                                stream=True
                            )
                            for chunk in stream:
                                if chunk.choices and len(chunk.choices) > 0:
                                    delta = chunk.choices[0].delta
                                    if delta.content:
                                        full_response += delta.content
                                        stream_box.markdown(full_response + "â–Œ")
                            stream_box.markdown(full_response)
                            st.session_state.messages.append({"role": "assistant", "content": full_response})
                        except Exception as e:
                            st.error(f"AI å“åº”ä¸­æ–­: {str(e)}")
            else:
                st.error("AI å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
