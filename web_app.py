import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import math
import json

# ================= 1. é¡µé¢é…ç½® =================
st.set_page_config(
    page_title="æ™ºèƒ½ç”µè·¯åŠ©æ•™å°ç”µ",
    page_icon="âš¡ï¸",
    layout="wide"
)

# ================= 2. ä¾§è¾¹æ ï¼šå°ç”µçš„è°ƒè¯•é¢æ¿ =================
st.sidebar.title("âš™ï¸ å°ç”µè°ƒè¯•å°")
st.sidebar.info("å¦‚æœè§‰å¾—å°ç”µçœ¼ç›ä¸å‡†ï¼Œå¯ä»¥åœ¨è¿™é‡Œå¾®è°ƒï¼š")

# é»˜è®¤å‚æ•°ï¼šè‡ªä¿¡åº¦ 0.10ï¼Œåˆ¤å®šè·ç¦» 60 (å®½æ¾ä¸€ç‚¹ï¼Œé˜²æ­¢è¯¯åˆ¤)
CONF_THRESHOLD = st.sidebar.slider("AI è‡ªä¿¡åº¦ (Conf)", 0.05, 1.0, 0.10, 0.05)
DIST_THRESHOLD = st.sidebar.slider("åˆ¤å®šè·ç¦» (Pixel)", 20, 100, 60, 5)

# ================= 3. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° =================

@st.cache_resource
def load_resources():
    """åŠ è½½æ¨¡å‹ã€åŸºå‡†å›¾å’Œåæ ‡"""
    try:
        model = YOLO('best.pt')
        base_img = cv2.imread('base_fixed.jpg')
        if base_img is None: return None, None, None, "âŒ æ‰¾ä¸åˆ° base_fixed.jpg"
        
        with open('board_config_fixed.json', 'r', encoding='utf-8') as f:
            pin_coords = json.load(f)
            
        return model, base_img, pin_coords, "OK"
    except Exception as e:
        return None, None, None, str(e)

# åˆå§‹åŒ–èµ„æº
model, base_img, pin_coords, msg = load_resources()
if msg != "OK": st.error(f"å°ç”µå¯åŠ¨å¤±è´¥: {msg}"); st.stop()

# å‡†å¤‡å¤‡ç”¨å¯¹é½ç‰¹å¾ (ORB)
orb = cv2.ORB_create(nfeatures=5000)
kp_base, des_base = orb.detectAndCompute(cv2.cvtColor(base_img, cv2.COLOR_BGR2GRAY), None)
h_ref, w_ref = base_img.shape[:2]

def check_color_in_roi(img, x, y, radius, target_color):
    """
    ğŸš‘ æ€¥æ•‘åŒ…ï¼šå¦‚æœ YOLO æ²¡çœ‹æ¸…ï¼Œå°ç”µç”¨æ”¾å¤§é•œå»æ‰¾é¢œè‰²
    """
    x, y, r = int(x), int(y), int(radius)
    h, w = img.shape[:2]
    # è¾¹ç•Œæ£€æŸ¥
    y1, y2 = max(0, y-r), min(h, y+r)
    x1, x2 = max(0, x-r), min(w, x+r)
    roi = img[y1:y2, x1:x2]
    if roi.size == 0: return False

    # è½¬ HSV é¢œè‰²ç©ºé—´
    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
    mask = None
    
    if target_color == 'red':
        # çº¢è‰²è·¨è¶Š 0åº¦ å’Œ 180åº¦
        lower1 = np.array([0, 100, 80])
        upper1 = np.array([10, 255, 255])
        lower2 = np.array([170, 100, 80])
        upper2 = np.array([180, 255, 255])
        mask = cv2.inRange(hsv, lower1, upper1) + cv2.inRange(hsv, lower2, upper2)
        
    elif target_color == 'black':
        # é»‘è‰²çœ‹äº®åº¦(V)
        lower = np.array([0, 0, 0])
        upper = np.array([180, 255, 60]) # V < 60 ç®—é»‘
        mask = cv2.inRange(hsv, lower, upper)

    # åªè¦åŒºåŸŸå†…æœ‰ 10% æ˜¯ç›®æ ‡é¢œè‰²ï¼Œå°±ç®—æ‰¾åˆ°äº†
    if mask is not None:
        ratio = cv2.countNonZero(mask) / (roi.shape[0] * roi.shape[1])
        return ratio > 0.10 
    return False

def order_points(pts):
    """ è¾…åŠ©å‡½æ•°ï¼šæ•´ç†å››ä¸ªè§’ç‚¹é¡ºåº """
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]; rect[2] = pts[np.argmax(s)]
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]; rect[3] = pts[np.argmax(diff)]
    return rect

def align_image(raw_img):
    """ åŒä¿é™©å¯¹é½ï¼šä¼˜å…ˆæ‰¾ç»¿æ¿å­ï¼Œæ‰¾ä¸åˆ°å†æ‰¾ç‰¹å¾ç‚¹ """
    # --- ç­–ç•¥A: é¢œè‰²è½®å»“ (Green Contour) ---
    try:
        hsv = cv2.cvtColor(raw_img, cv2.COLOR_BGR2HSV)
        # æå–ç»¿è‰²
        mask = cv2.inRange(hsv, np.array([30, 40, 40]), np.array([90, 255, 255]))
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((5,5), np.uint8))
        cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if len(cnts) > 0:
            c = max(cnts, key=cv2.contourArea)
            if cv2.contourArea(c) > 20000: # é¢ç§¯å¤Ÿå¤§æ‰ç®—
                peri = cv2.arcLength(c, True)
                approx = cv2.approxPolyDP(c, 0.02 * peri, True)
                if len(approx) == 4:
                    dst = np.array([[0,0], [w_ref-1,0], [w_ref-1,h_ref-1], [0,h_ref-1]], dtype="float32")
                    M = cv2.getPerspectiveTransform(order_points(approx.reshape(4,2)), dst)
                    return cv2.warpPerspective(raw_img, M, (w_ref, h_ref))
    except: pass

    # --- ç­–ç•¥B: ç‰¹å¾ç‚¹ (ORB) ---
    gray = cv2.cvtColor(raw_img, cv2.COLOR_BGR2GRAY)
    kp, des = orb.detectAndCompute(gray, None)
    if des is None: return None
    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
    matches = sorted(bf.match(des_base, des), key=lambda x: x.distance)
    good = matches[:int(len(matches)*0.15)]
    if len(good) < 4: return None
    
    src_pts = np.float32([kp[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)
    dst_pts = np.float32([kp_base[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)
    M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
    return cv2.warpPerspective(raw_img, M, (w_ref, h_ref)) if M is not None else None

# ================= 4. ä¸»ç•Œé¢é€»è¾‘ =================
st.title("âš¡ï¸ æ™ºèƒ½ç”µè·¯åŠ©æ•™å°ç”µ")
st.markdown("---")

col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("ğŸ“¸ 1. ä¸Šä¼ ä½œä¸š")
    uploaded_file = st.file_uploader("è¯·æŠŠç…§ç‰‡æ‹–è¿›æ¥", type=['jpg', 'jpeg', 'png'])

if uploaded_file:
    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
    raw_img = cv2.imdecode(file_bytes, 1)
    with col1: st.image(cv2.cvtColor(raw_img, cv2.COLOR_BGR2RGB), caption="å­¦ç”Ÿä½œä¸šåŸå›¾", use_column_width=True)

    # --- å¼€å§‹åˆ†æ ---
    with col2:
        st.subheader("ğŸ“ 2. å°ç”µæ‰¹æ”¹ç»“æœ")
        
        aligned_img = align_image(raw_img)
        if aligned_img is None:
            st.error("âš ï¸ å°ç”µçœ‹ä¸æ¸…ç”µè·¯æ¿ï¼è¯·ç¡®ä¿æ‹æ‘„æ¸…æ™°ï¼Œå»ºè®®ä¸‹é¢å«ä¸€å¼ ç™½çº¸ã€‚")
        else:
            # 1. YOLO åˆç­›
            results = model(aligned_img, conf=CONF_THRESHOLD, iou=0.8, verbose=False)[0]
            detected_heads = [{"color": model.names[int(b.cls[0])], "x": b.xywh[0][0].item(), "y": b.xywh[0][1].item()} for b in results.boxes]

            # 2. åæ ‡å½’ä½ (æ”¯æŒä¸€å­”å¤šçº¿)
            board_status = {}
            for pin, (px, py) in pin_coords.items():
                board_status[pin] = {"connected": False, "colors": []}
                for head in detected_heads:
                    if math.sqrt((head['x']-px)**2 + (head['y']-py)**2) < DIST_THRESHOLD:
                        board_status[pin]["connected"] = True
                        board_status[pin]["colors"].append(head['color'])

            # 3. åˆ¤å· + æ€¥æ•‘åŒ…é€»è¾‘
            errors, praises = [], []

            # --- è§„åˆ™1: VCC (çº¢è‰²) ---
            vcc_pin = "U1_Pin_16 (VCC)"
            vcc = board_status[vcc_pin]
            px, py = pin_coords[vcc_pin]
            
            # è¡¥ä¸ï¼šå¦‚æœæ²¡è¿ï¼Œæˆ–è€…æ²¡æ£€æµ‹åˆ°çº¢çº¿ï¼Œå¯åŠ¨é¢œè‰²å¼ºä¾¦æµ‹
            if not vcc['connected'] or "head_red" not in vcc['colors']:
                if check_color_in_roi(aligned_img, px, py, 20, 'red'):
                    vcc['connected'] = True
                    if "head_red" not in vcc['colors']: vcc['colors'].append("head_red")
            
            if not vcc['connected']:
                errors.append("âŒ **èŠ¯ç‰‡æ²¡ä¾›ç”µ**ï¼šU1 Pin 16 æœªè¿æ¥ã€‚")
            elif "head_red" in vcc['colors']:
                praises.append("ç”µæº VCC è¿æ¥æ­£ç¡® (çº¢è‰²)")
            else:
                errors.append(f"âš ï¸ **é¢œè‰²ä¸è§„èŒƒ**ï¼šVCC å»ºè®®çº¢çº¿ï¼Œå°ç”µæ£€æµ‹åˆ° {vcc['colors']}ã€‚")

            # --- è§„åˆ™2: GND (é»‘è‰²) ---
            gnd_pin = "U1_Pin_8 (GND)"
            gnd = board_status[gnd_pin]
            gx, gy = pin_coords[gnd_pin]
            
            # è¡¥ä¸ï¼šå¯åŠ¨é»‘è‰²å¼ºä¾¦æµ‹
            if not gnd['connected'] or "head_black" not in gnd['colors']:
                if check_color_in_roi(aligned_img, gx, gy, 20, 'black'):
                    gnd['connected'] = True
                    if "head_black" not in gnd['colors']: gnd['colors'].append("head_black")

            if not gnd['connected']:
                errors.append("âŒ **èŠ¯ç‰‡æ²¡æ¥åœ°**ï¼šU1 Pin 8 æœªè¿æ¥ã€‚")
            elif "head_black" in gnd['colors']:
                praises.append("æ¥åœ° GND è¿æ¥æ­£ç¡® (é»‘è‰²)")
            else:
                errors.append(f"âš ï¸ **é¢œè‰²ä¸è§„èŒƒ**ï¼šGND å»ºè®®é»‘çº¿ï¼Œå°ç”µæ£€æµ‹åˆ° {gnd['colors']}ã€‚")

            # --- è§„åˆ™3: æ•°ç ç®¡ ---
            seg_pins = ["U1_Pin_6 (Seg F)", "U1_Pin_7 (Seg G)", "U1_Pin_9 (Seg D)", "U1_Pin_10 (Seg A)", "U1_Pin_11 (Seg E)", "U1_Pin_12 (Seg B)", "U1_Pin_13 (Seg C)"]
            conn_count = sum(1 for p in seg_pins if board_status[p]['connected'])
            if conn_count < 7: errors.append(f"âŒ **æ•°ç ç®¡ç¼ºç¬”ç”»**ï¼šåªæ¥äº† {conn_count}/7 æ ¹ã€‚")
            else: praises.append(f"æ•°ç ç®¡ 7 æ®µé©±åŠ¨çº¿å®Œæ•´")

            # æ˜¾ç¤ºç»“æœ
            if errors: 
                st.warning(f"å°ç”µå‘ç° {len(errors)} ä¸ªé—®é¢˜ï¼Œè¯·ä¿®æ”¹ï¼š")
                for e in errors: st.markdown(e)
            else: 
                st.success("ğŸ‰ å®Œç¾ï¼ç”µè·¯è¿æ¥æ­£ç¡®ï¼å°ç”µç»™æ»¡åˆ†ï¼"); st.balloons()
            
            if praises:
                with st.expander("ğŸ‘€ æŸ¥çœ‹åšå¾—å¥½çš„åœ°æ–¹"):
                    for p in praises: st.write(f"âœ… {p}")

            # ç”»å›¾ (è“è‰²=åˆ¤å®šåŒºï¼Œç»¿è‰²=è¯†åˆ«ç‚¹)
            viz = aligned_img.copy()
            for p, (px, py) in pin_coords.items():
                cv2.circle(viz, (int(px), int(py)), DIST_THRESHOLD, (255, 0, 0), 2) # åˆ¤å®šåœˆ
            for h in detected_heads:
                cv2.circle(viz, (int(h['x']), int(h['y'])), 6, (0, 255, 0), -1) # è¯†åˆ«ç‚¹
            st.image(cv2.cvtColor(viz, cv2.COLOR_BGR2RGB), caption="å°ç”µè§†è§‰åˆ†æå›¾ (è“åœˆ=åˆ¤å®šåŒº)", use_column_width=True)

else:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¸Šä¼ å›¾ç‰‡ï¼Œå°ç”µéšæ—¶å‡†å¤‡ç€ï¼")