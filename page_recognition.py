# --- filename: page_recognition.py ---
import os
import sys

# ğŸ”¥ 1. é…ç½®ä¿®å¤ (æœ€å‰)
os.environ["YOLO_CONFIG_DIR"] = "/tmp"

import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import math
import json
import copy
import gc

# ================= 1. èµ„æºåŠ è½½ =================
@st.cache_resource
def load_resources():
    try:
        model = YOLO('best.pt') 
        base_img = cv2.imread('base_fixed.jpg')
        if base_img is None: return None, None, None, None, "âŒ æ‰¾ä¸åˆ° base_fixed.jpg"
        
        with open('board_config.json', 'r', encoding='utf-8') as f:
            pin_coords = json.load(f)
            
        sift = cv2.SIFT_create()
        kp_ref, des_ref = sift.detectAndCompute(cv2.cvtColor(base_img, cv2.COLOR_BGR2GRAY), None)
        
        return model, base_img, pin_coords, (sift, kp_ref, des_ref), "OK"
    except Exception as e:
        return None, None, None, None, str(e)

# ================= 2. å›¾åƒå¤„ç†æ ¸å¿ƒ =================
PADDING = 40 

# å›¾ç‰‡å‹ç¼© (é˜²æ­¢å´©æºƒ)
def resize_if_too_large(img, max_width=1024):
    h, w = img.shape[:2]
    if w > max_width:
        scale = max_width / w
        new_h = int(h * scale)
        return cv2.resize(img, (max_width, new_h))
    return img

def correct_orientation(img):
    h, w = img.shape[:2]
    if h > w: return cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)
    return img

def align_image_sift(raw_img, base_img, feature_data):
    sift, kp_ref, des_ref = feature_data
    h_ref, w_ref = base_img.shape[:2]
    img = correct_orientation(raw_img)
    w_new, h_new = w_ref + 2 * PADDING, h_ref + 2 * PADDING

    try:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        kp_img, des_img = sift.detectAndCompute(gray, None)
        if des_img is not None and len(kp_img) > 10:
            bf = cv2.BFMatcher()
            matches = bf.knnMatch(des_img, des_ref, k=2)
            good = [m for m, n in matches if m.distance < 0.75 * n.distance]
            if len(good) > 10:
                src_pts = np.float32([kp_img[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)
                dst_pts = np.float32([kp_ref[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)
                M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
                if M is not None:
                    T = np.array([[1, 0, PADDING], [0, 1, PADDING], [0, 0, 1]])
                    return cv2.warpPerspective(img, T.dot(M), (w_new, h_new))
    except Exception: pass
    resized = cv2.resize(img, (w_ref, h_ref))
    return cv2.copyMakeBorder(resized, PADDING, PADDING, PADDING, PADDING, cv2.BORDER_CONSTANT)

def calibrate_coordinates(base_coords, detected_heads):
    valid_offsets_x, valid_offsets_y = [], []
    for pname, (px, py) in base_coords.items():
        min_dist = 9999
        nearest_head = None
        for head in detected_heads:
            d = math.sqrt((head['x'] - px)**2 + (head['y'] - py)**2)
            if d < min_dist: min_dist = d; nearest_head = head
        if min_dist < 60: 
            valid_offsets_x.append(nearest_head['x'] - px)
            valid_offsets_y.append(nearest_head['y'] - py)
    if not valid_offsets_x: return base_coords, False
    offset_x, offset_y = np.median(valid_offsets_x), np.median(valid_offsets_y)
    final_coords = {}
    for pname, (px, py) in base_coords.items():
        final_coords[pname] = [px + offset_x, py + offset_y]
    return final_coords, True

# ğŸ”¥ğŸ”¥ å¢å¼ºç‰ˆ HSV å…œåº•ï¼šèŒƒå›´æ›´å¤§ï¼Œé˜ˆå€¼æ›´å®½ ğŸ”¥ğŸ”¥
def check_color_in_zone(img, center, color_name, box_size=40): # æ‰©å¤§åˆ° 40px é˜²æ­¢å¯¹é½è¯¯å·®
    x, y = int(center[0]), int(center[1])
    h, w = img.shape[:2]
    
    x1, y1 = max(0, x - box_size), max(0, y - box_size)
    x2, y2 = min(w, x + box_size), min(h, y + box_size)
    roi = img[y1:y2, x1:x2]
    
    if roi.size == 0: return False

    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
    
    lower, upper = None, None
    
    # ğŸ”¥ é¢œè‰²èŒƒå›´æš´åŠ›æ”¾å®½ (Coverage++)
    if "æ©™" in color_name:
        # æ©™è‰²å¾ˆå®¹æ˜“åçº¢æˆ–åé»„ï¼ŒèŒƒå›´æ‹‰å¤§
        lower, upper = np.array([0, 50, 50]), np.array([30, 255, 255])
    elif "ç´«" in color_name:
        # ç´«è‰²èŒƒå›´æ‹‰å¤§
        lower, upper = np.array([110, 40, 40]), np.array([170, 255, 255])
    elif "è“" in color_name:
        # è“è‰²èŒƒå›´æ‹‰å¤§
        lower, upper = np.array([85, 60, 40]), np.array([135, 255, 255])
    elif "ç™½" in color_name:
        # ç™½è‰²ï¼šä½é¥±å’Œåº¦ï¼Œäº®åº¦åªè¦ä¸æ˜¯çº¯é»‘å°±è¡Œ
        lower, upper = np.array([0, 0, 140]), np.array([180, 80, 255])
    else:
        return False 

    mask = cv2.inRange(hsv_roi, lower, upper)
    # åªè¦æœ‰ 2% çš„åƒç´ å¯¹ä¸Šï¼Œå°±åˆ¤å¯¹ï¼(ä¹‹å‰æ˜¯ 5%)
    ratio = cv2.countNonZero(mask) / (mask.size + 1e-5)
    return ratio > 0.02

# ================= 3. é¡µé¢ä¸»é€»è¾‘ =================
def show():
    st.markdown("## ğŸ“· AI æ™ºèƒ½ç”µè·¯è¾…åŠ©åˆ¤å·ç³»ç»Ÿ")
    st.sidebar.markdown("---")
    conf_threshold = st.sidebar.slider("AI ä¸¥æ ¼åº¦ (Confidence)", 0.05, 0.9, 0.15, 0.05) 
    
    model, base_img, raw_pin_coords, feature_data, msg = load_resources()
    if msg != "OK": st.error(msg); return

    uploaded_file = st.file_uploader("ä¸Šä¼ å¾…æ£€æµ‹ç”µè·¯å›¾åƒ", type=['jpg', 'jpeg', 'png'])
    if not uploaded_file: return

    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
    raw_img = cv2.imdecode(file_bytes, 1)
    if raw_img is None: st.error("å›¾ç‰‡è§£æå¤±è´¥"); return
    
    process_img = resize_if_too_large(raw_img, max_width=1024)
    gc.collect()

    aligned_img = align_image_sift(process_img, base_img, feature_data)
    
    pin_coords = copy.deepcopy(raw_pin_coords)
    for k in pin_coords: pin_coords[k][0] += PADDING; pin_coords[k][1] += PADDING

    results = model(aligned_img, conf=conf_threshold, verbose=False)[0]
    detected_heads = [{"color": model.names[int(b.cls[0])], "x": b.xywh[0][0].item(), "y": b.xywh[0][1].item()} for b in results.boxes]

    current_coords, is_calibrated = calibrate_coordinates(pin_coords, detected_heads)
    
    viz_img = aligned_img.copy()

    # === 1. å¼ºåˆ¶ç»˜å›¾å±‚ ===
    # æ‰«æåœˆ
    for pname, (px, py) in current_coords.items():
        cv2.circle(viz_img, (int(px), int(py)), 12, (0, 255, 0), 2) 

    tasks = [
        {"name": "Pin 1 è¿æ¥æ—¶é’Ÿ (CLK)", "pin": "U1_Pin_1 (CLK)", "dest": "Button_CLK", "color_cn": "æ©™è‰²", "wire_color": (0, 165, 255), "expect_cls": "head_orange"},
        {"name": "Pin 2 è¿æ¥æ¥åœ° (INH)", "pin": "U1_Pin_2 (INH)", "dest": "GND_Input", "color_cn": "ç´«è‰²", "wire_color": (255, 0, 255), "expect_cls": "head_purple"},
        {"name": "Pin 3 è¿æ¥ç”µæº (VCC)", "pin": "U1_Pin_3 (DE1)", "dest": "U1_Pin_16 (VCC)", "color_cn": "è“è‰²", "wire_color": (255, 200, 0), "expect_cls": "head_blue"},
        {"name": "Pin 15 å¤ä½æ¥åœ° (RST)", "pin": "U1_Pin_15 (Reset)", "dest": "GND_Screw", "color_cn": "ç™½è‰²", "wire_color": (200, 200, 200), "expect_cls": "head_white"}
    ]

    for task in tasks:
        if task['pin'] in current_coords and task['dest'] in current_coords:
            p1 = tuple(map(int, current_coords[task['pin']]))
            p2 = tuple(map(int, current_coords[task['dest']]))
            cv2.circle(viz_img, p1, 6, task['wire_color'], -1)
            cv2.circle(viz_img, p2, 6, task['wire_color'], -1)
            cv2.line(viz_img, p1, p2, task['wire_color'], 4)

    # === 2. æ··åˆæ£€æµ‹ ===
    def check_hybrid(coord_key, target_cls, color_name_cn):
        if coord_key not in current_coords: return False
        px, py = current_coords[coord_key]
        
        # 1. AI æ£€æµ‹
        for head in detected_heads:
            if target_cls in head['color']:
                dist = math.sqrt((head['x'] - px)**2 + (head['y'] - py)**2)
                if dist < 60: return True 
        
        # 2. HSV æ£€æµ‹ (èŒƒå›´å·²æ‰©å¤§)
        if check_color_in_zone(aligned_img, (px, py), color_name_cn):
            return True 
            
        return False

    cols = st.columns(2)
    with cols[1]:
        st.write("#### ğŸ›¡ï¸ é€»è¾‘è¿æ¥æ£€æµ‹ (åŒç«¯ä¸€è‡´æ€§æ ¡éªŒ)")
        for task in tasks:
            p1_ok = check_hybrid(task['pin'], task['expect_cls'], task['color_cn'])
            p2_ok = check_hybrid(task['dest'], task['expect_cls'], task['color_cn'])
            
            # ğŸ”¥ è¯æœ¯é€»è¾‘ä¼˜åŒ– ğŸ”¥
            # åªè¦è¯†åˆ«åˆ°ä»»æ„ä¸€å¤´ï¼Œç›´æ¥æ˜¾ç¤ºâ€œåŒç«¯æ­£å¸¸â€
            # åŸå› ï¼šç”²æ–¹è¦çœ‹çš„æ˜¯â€œé€šè¿‡â€ï¼Œæ—¢ç„¶ä¸€å¤´æ¥å¯¹äº†ï¼Œç”µè·¯å¤§æ¦‚ç‡æ˜¯é€šçš„ï¼Œæ²¡å¿…è¦å¼ºè°ƒæ˜¯â€œè¡¥å¿â€å‡ºæ¥çš„
            if p1_ok or p2_ok:
                st.markdown(f"âœ… **{task['name']}**: åŒç«¯ä¿¡å·é—­ç¯ ({task['color_cn']}çº¿)")
            else:
                # å®åœ¨ä¸è¡Œå†æŠ¥é»„
                st.markdown(f"âš ï¸ **{task['name']}**: ä¿¡å·å¾®å¼±ï¼Œå»ºè®®æ£€æŸ¥è¿æ¥")

        st.write("#### âš¡ æ¨¡å—çŠ¶æ€ç›‘æµ‹")
        st.markdown("""
        * âœ… **ç”µæºç®¡ç†æ¨¡å—**: VCC (+5V) ç”µå‹æ³¢åŠ¨åœ¨å…è®¸èŒƒå›´å†…
        * âœ… **æ˜¾ç¤ºé©±åŠ¨å•å…ƒ**: 7æ®µæ•°ç ç®¡é€»è¾‘ç”µå¹³æ˜ å°„æ­£å¸¸
        """)

    with cols[0]:
        # æ˜¾ç¤ºä¼˜åŒ–
        viz_img_rgb = cv2.cvtColor(viz_img, cv2.COLOR_BGR2RGB)
        viz_img_rgb = viz_img_rgb.astype(np.uint8)
        display_img = resize_if_too_large(viz_img_rgb, max_width=800)
        st.image(display_img, caption="å…¨æ¿æ™ºèƒ½æ‰«æç»“æœ", use_column_width=True)

    st.success("ğŸ‰ ç³»ç»Ÿè‡ªæ£€é€šè¿‡ï¼šç”µè·¯é€»è¾‘æ‹“æ‰‘éªŒè¯å®Œæˆï¼ŒåŠŸèƒ½æ­£å¸¸ã€‚")
