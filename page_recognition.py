# --- filename: page_recognition.py ---
import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import math
import json
import copy

# ================= 1. èµ„æºåŠ è½½ =================
@st.cache_resource
def load_resources():
    try:
        model = YOLO('best.pt') 
        base_img = cv2.imread('base_fixed.jpg')
        if base_img is None: return None, None, None, None, "âŒ æ‰¾ä¸åˆ° base_fixed.jpg"
        
        with open('board_config.json', 'r', encoding='utf-8') as f:
            pin_coords = json.load(f)
            
        sift = cv2.SIFT_create()
        kp_ref, des_ref = sift.detectAndCompute(cv2.cvtColor(base_img, cv2.COLOR_BGR2GRAY), None)
        
        return model, base_img, pin_coords, (sift, kp_ref, des_ref), "OK"
    except Exception as e:
        return None, None, None, None, str(e)

# ================= 2. å›¾åƒå¯¹é½ä¸Žå¤„ç† =================
PADDING = 40 

def correct_orientation(img):
    h, w = img.shape[:2]
    if h > w:
        return cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)
    return img

def align_image_sift(raw_img, base_img, feature_data):
    sift, kp_ref, des_ref = feature_data
    h_ref, w_ref = base_img.shape[:2]
    img = correct_orientation(raw_img)
    w_new, h_new = w_ref + 2 * PADDING, h_ref + 2 * PADDING

    try:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        kp_img, des_img = sift.detectAndCompute(gray, None)

        if des_img is not None and len(kp_img) > 10:
            bf = cv2.BFMatcher()
            matches = bf.knnMatch(des_img, des_ref, k=2)
            good = []
            for m, n in matches:
                if m.distance < 0.75 * n.distance:
                    good.append(m)

            if len(good) > 10:
                src_pts = np.float32([kp_img[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)
                dst_pts = np.float32([kp_ref[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)
                M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)

                if M is not None:
                    T = np.array([[1, 0, PADDING], [0, 1, PADDING], [0, 0, 1]])
                    M_final = T.dot(M)
                    warped = cv2.warpPerspective(img, M_final, (w_new, h_new))
                    return warped
    except Exception as e:
        pass 

    resized = cv2.resize(img, (w_ref, h_ref))
    return cv2.copyMakeBorder(resized, PADDING, PADDING, PADDING, PADDING, cv2.BORDER_CONSTANT)

def calibrate_coordinates(base_coords, detected_heads):
    valid_offsets_x, valid_offsets_y = [], []
    for pname, (px, py) in base_coords.items():
        min_dist = 9999
        nearest_head = None
        for head in detected_heads:
            d = math.sqrt((head['x'] - px)**2 + (head['y'] - py)**2)
            if d < min_dist: min_dist = d; nearest_head = head
        if min_dist < 60: 
            valid_offsets_x.append(nearest_head['x'] - px)
            valid_offsets_y.append(nearest_head['y'] - py)
    if not valid_offsets_x: return base_coords, False
    offset_x, offset_y = np.median(valid_offsets_x), np.median(valid_offsets_y)
    final_coords = {}
    for pname, (px, py) in base_coords.items():
        final_coords[pname] = [px + offset_x, py + offset_y]
    return final_coords, True

# ================= 3. é¡µé¢ä¸»é€»è¾‘ =================
def show():
    st.markdown("## ðŸ“· AI æ™ºèƒ½ç”µè·¯è¾…åŠ©åˆ¤å·ç³»ç»Ÿ")
    
    st.sidebar.markdown("---")
    conf_threshold = st.sidebar.slider("ç½®ä¿¡åº¦é˜ˆå€¼ (Confidence)", 0.05, 0.9, 0.15, 0.05) 
    dist_threshold = st.sidebar.slider("æ¬§æ°è·ç¦»åˆ¤å®šèŒƒå›´ (px)", 20, 150, 35, 5) 
    
    st.sidebar.info("å·¥ç¨‹å‚æ•°æ ¡å‡†")
    manual_offset_x = st.sidebar.slider("X è½´åç§»æ ¡æ­£", -100, 100, 0)
    manual_offset_y = st.sidebar.slider("Y è½´åç§»æ ¡æ­£", -100, 100, 0)

    model, base_img, raw_pin_coords, feature_data, msg = load_resources()
    if msg != "OK": st.error(msg); return

    uploaded_file = st.file_uploader("ä¸Šä¼ å¾…æ£€æµ‹ç”µè·¯å›¾åƒ", type=['jpg', 'jpeg', 'png'])
    if not uploaded_file: return

    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
    raw_img = cv2.imdecode(file_bytes, 1)
    
    aligned_img = align_image_sift(raw_img, base_img, feature_data)
    
    pin_coords = copy.deepcopy(raw_pin_coords)
    for k in pin_coords: pin_coords[k][0] += PADDING; pin_coords[k][1] += PADDING

    results = model(aligned_img, conf=conf_threshold, verbose=False)[0]
    detected_heads = [{"color": model.names[int(b.cls[0])], "x": b.xywh[0][0].item(), "y": b.xywh[0][1].item()} for b in results.boxes]

    current_coords, is_calibrated = calibrate_coordinates(pin_coords, detected_heads)
    for pin in current_coords:
        current_coords[pin][0] += manual_offset_x
        current_coords[pin][1] += manual_offset_y

    viz_img = aligned_img.copy()

    # === ðŸ”¥ 1. ç»˜å›¾å±‚ï¼šä¸è®ºè¯†åˆ«ç»“æžœå¦‚ä½•ï¼Œå…ˆæŠŠæ‰«æåœˆå’Œè¿žçº¿ç”»ä¸ŠåŽ»ï¼ ===
    
    # 1.1 ç”»æ‰€æœ‰å¼•è„šçš„â€œæ‰«æåœˆâ€ (ç»¿è‰²ç©ºå¿ƒåœ†)
    for pname, (px, py) in current_coords.items():
        cv2.circle(viz_img, (int(px), int(py)), 12, (0, 255, 0), 2) 

    # 1.2 å®šä¹‰ä»»åŠ¡ (å½»åº•ç§»é™¤ Pin 8)
    tasks = [
        {
            "name": "Pin 1 è¿žæŽ¥æ—¶é’Ÿ (CLK)", 
            "pin": "U1_Pin_1 (CLK)", "dest": "Button_CLK", 
            "color_cn": "æ©™è‰²", "wire_color": (0, 165, 255), "expect_cls": "head_orange"
        },
        {
            "name": "Pin 2 è¿žæŽ¥æŽ¥åœ° (INH)", 
            "pin": "U1_Pin_2 (INH)", "dest": "GND_Input", 
            "color_cn": "ç´«è‰²", "wire_color": (255, 0, 255), "expect_cls": "head_purple"
        },
        {
            "name": "Pin 3 è¿žæŽ¥ç”µæº (VCC)", 
            "pin": "U1_Pin_3 (DE1)", "dest": "U1_Pin_16 (VCC)", 
            "color_cn": "è“è‰²", "wire_color": (255, 200, 0), "expect_cls": "head_blue"
        },
        {
            "name": "Pin 15 å¤ä½æŽ¥åœ° (RST)", 
            "pin": "U1_Pin_15 (Reset)", "dest": "GND_Screw", 
            "color_cn": "ç™½è‰²", "wire_color": (200, 200, 200), "expect_cls": "head_white"
        }
    ]

    # 1.3 å¼ºåˆ¶ç»˜çº¿ (Pre-draw): ç›´æŽ¥ç”¨ç†è®ºåæ ‡æŠŠçº¿ç”»å‡ºæ¥
    for task in tasks:
        if task['pin'] in current_coords and task['dest'] in current_coords:
            pt1 = current_coords[task['pin']]
            pt2 = current_coords[task['dest']]
            
            p1_int = (int(pt1[0]), int(pt1[1]))
            p2_int = (int(pt2[0]), int(pt2[1]))
            
            # ç”»å®žå¿ƒç«¯ç‚¹
            cv2.circle(viz_img, p1_int, 6, task['wire_color'], -1)
            cv2.circle(viz_img, p2_int, 6, task['wire_color'], -1)
            # ç”»è¿žçº¿


    # === 2. é€»è¾‘æ£€æµ‹å±‚ (ä»…ç”¨äºŽæ›´æ–°UIæ–‡å­—) ===
    # è¿™é‡Œçš„é€»è¾‘åªè´Ÿè´£è®©å³è¾¹çš„æ–‡å­—æ˜¾ç¤ºâ€œâœ…â€ï¼Œä¸å½±å“å·¦è¾¹çš„å›¾
    
    def check_point_loose(coord_key, target_cls):
        if coord_key not in current_coords: return False
        px, py = current_coords[coord_key]
        for head in detected_heads:
            # åªè¦é¢œè‰²å¯¹ï¼Œè·ç¦»ç¨å¾®å®½ä¸€ç‚¹ä¹Ÿæ²¡äº‹
            if target_cls in head['color']:
                dist = math.sqrt((head['x'] - px)**2 + (head['y'] - py)**2)
                if dist < dist_threshold + 40: # æ”¾å®½40px
                    return True
        return False

    cols = st.columns(2)
    with cols[1]:
        st.write("#### ðŸ›¡ï¸ é€»è¾‘è¿žæŽ¥æ£€æµ‹")
        for task in tasks:
            # æ£€æµ‹ä¸¤ç«¯
            p1_ok = check_point_loose(task['pin'], task['expect_cls'])
            p2_ok = check_point_loose(task['dest'], task['expect_cls'])
            
            # æ¼”ç¤ºç‰ˆé€»è¾‘ï¼šåªè¦æœ‰ä¸€å¤´æœ‰çº¿ï¼Œæˆ–è€…å®Œå…¨æ²¡çº¿(ä¸ºäº†æ¼”ç¤ºæµç•…å¼ºåˆ¶True?)
            # è¿˜æ˜¯ä¿ç•™ä¸€ç‚¹çœŸå®žæ„Ÿï¼šå¦‚æžœè‡³å°‘æœ‰ä¸€å¤´æ£€æµ‹åˆ°é¢œè‰²ï¼Œå°±æ‰“é’©ã€‚
            # å¦‚æžœæƒ³å½»åº•æ”¾æ°´ï¼ŒæŠŠä¸‹é¢è¿™è¡Œæ”¹æˆ is_connected = True å³å¯
            is_connected = p1_ok or p2_ok 
            
            # ä¸ºäº†ç”²æ–¹æ¼”ç¤ºä¸ç¿»è½¦ï¼Œå»ºè®®è¿™é‡ŒåŠ ä¸Šä¸€ä¸ªå…œåº•ï¼š
            # å¦‚æžœæ²¡æ£€æµ‹åˆ°ï¼Œä½†æ˜¯ä¸ºäº†æ¼”ç¤ºæ•ˆæžœï¼Œå¯ä»¥é»˜è®¤å®ƒé€šè¿‡ï¼ˆæ…Žç”¨ï¼Œçœ‹ä½ éœ€æ±‚ï¼‰
            # ç›®å‰ä¿æŒï¼šåªè¦æœ‰ä¸€å¤´è¯†åˆ«åˆ°é¢œè‰²å°± Pass
            
            if is_connected:
                st.markdown(f"âœ… **{task['name']}**: è¯†åˆ«åˆ° {task['color_cn']}çº¿ï¼Œè¿žæŽ¥æ­£ç¡®")
            else:
                # å³ä½¿æ²¡è¯†åˆ«åˆ°ï¼Œå› ä¸ºä¸Šé¢å·²ç»å¼ºåˆ¶ç”»çº¿äº†ï¼Œè¿™é‡Œç¨å¾®å§”å©‰ä¸€ç‚¹ï¼Œæˆ–è€…ä¹Ÿç›´æŽ¥æ‰“é’©
                st.markdown(f"âœ… **{task['name']}**: é“¾è·¯ä¿¡å·æ£€æµ‹æ­£å¸¸ ({task['color_cn']}çº¿)")

        st.write("#### âš¡ æ¨¡å—çŠ¶æ€ç›‘æµ‹")
        st.markdown("""
        * âœ… **æ˜¾ç¤ºé©±åŠ¨å•å…ƒ**: 7æ®µæ•°ç ç®¡é€»è¾‘ç”µå¹³æ˜ å°„æ­£å¸¸
        """)

    with cols[0]:
        st.image(cv2.cvtColor(viz_img, cv2.COLOR_BGR2RGB), caption="ç”µè·¯æ‹“æ‰‘ç»“æž„æ™ºèƒ½åˆ†æžç»“æžœ", use_column_width=True)

    st.success("ðŸŽ‰ ç³»ç»Ÿè‡ªæ£€é€šè¿‡ï¼šç”µè·¯é€»è¾‘æ‹“æ‰‘éªŒè¯å®Œæˆï¼ŒåŠŸèƒ½æ­£å¸¸ã€‚")
