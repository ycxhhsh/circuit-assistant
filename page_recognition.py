# --- filename: page_recognition.py ---
import os
import sys

# ðŸ”¥ 1. æ ¸å¿ƒä¿®å¤ï¼šé…ç½®ç›®å½•é‡å®šå‘ (å¿…é¡»åœ¨æœ€å¼€å¤´)
# è§£å†³ "user config directory is not writable" è­¦å‘Š
os.environ["YOLO_CONFIG_DIR"] = "/tmp"

import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import math
import json
import copy
import gc

# ================= 1. èµ„æºåŠ è½½ =================
@st.cache_resource
def load_resources():
    try:
        model = YOLO('best.pt') 
        base_img = cv2.imread('base_fixed.jpg')
        if base_img is None: return None, None, None, None, "âŒ æ‰¾ä¸åˆ° base_fixed.jpg"
        
        with open('board_config.json', 'r', encoding='utf-8') as f:
            pin_coords = json.load(f)
            
        sift = cv2.SIFT_create()
        kp_ref, des_ref = sift.detectAndCompute(cv2.cvtColor(base_img, cv2.COLOR_BGR2GRAY), None)
        
        return model, base_img, pin_coords, (sift, kp_ref, des_ref), "OK"
    except Exception as e:
        return None, None, None, None, str(e)

# ================= 2. å›¾åƒå¤„ç†ä¸ŽåŽ‹ç¼© =================
PADDING = 40 

# ðŸ”¥ 2. æ ¸å¿ƒä¿®å¤ï¼šå›¾ç‰‡åŽ‹ç¼©å‡½æ•°
# é˜²æ­¢ 4000px å¤§å›¾ç›´æŽ¥å¡žè¿›å†…å­˜å¯¼è‡´ "Oh no" å´©æºƒ
def resize_if_too_large(img, max_width=1024):
    h, w = img.shape[:2]
    if w > max_width:
        scale = max_width / w
        new_h = int(h * scale)
        return cv2.resize(img, (max_width, new_h))
    return img

def correct_orientation(img):
    h, w = img.shape[:2]
    if h > w:
        return cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)
    return img

def align_image_sift(raw_img, base_img, feature_data):
    sift, kp_ref, des_ref = feature_data
    h_ref, w_ref = base_img.shape[:2]
    img = correct_orientation(raw_img)
    w_new, h_new = w_ref + 2 * PADDING, h_ref + 2 * PADDING

    try:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        kp_img, des_img = sift.detectAndCompute(gray, None)

        if des_img is not None and len(kp_img) > 10:
            bf = cv2.BFMatcher()
            matches = bf.knnMatch(des_img, des_ref, k=2)
            good = []
            for m, n in matches:
                if m.distance < 0.75 * n.distance:
                    good.append(m)

            if len(good) > 10:
                src_pts = np.float32([kp_img[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)
                dst_pts = np.float32([kp_ref[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)
                M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)

                if M is not None:
                    T = np.array([[1, 0, PADDING], [0, 1, PADDING], [0, 0, 1]])
                    M_final = T.dot(M)
                    warped = cv2.warpPerspective(img, M_final, (w_new, h_new))
                    return warped
    except Exception as e:
        pass 

    resized = cv2.resize(img, (w_ref, h_ref))
    return cv2.copyMakeBorder(resized, PADDING, PADDING, PADDING, PADDING, cv2.BORDER_CONSTANT)

def calibrate_coordinates(base_coords, detected_heads):
    valid_offsets_x, valid_offsets_y = [], []
    for pname, (px, py) in base_coords.items():
        min_dist = 9999
        nearest_head = None
        for head in detected_heads:
            d = math.sqrt((head['x'] - px)**2 + (head['y'] - py)**2)
            if d < min_dist: min_dist = d; nearest_head = head
        if min_dist < 60: 
            valid_offsets_x.append(nearest_head['x'] - px)
            valid_offsets_y.append(nearest_head['y'] - py)
    if not valid_offsets_x: return base_coords, False
    offset_x, offset_y = np.median(valid_offsets_x), np.median(valid_offsets_y)
    final_coords = {}
    for pname, (px, py) in base_coords.items():
        final_coords[pname] = [px + offset_x, py + offset_y]
    return final_coords, True

# ================= 3. é¡µé¢ä¸»é€»è¾‘ =================
def show():
    st.markdown("## ðŸ“· AI æ™ºèƒ½ç”µè·¯è¾…åŠ©åˆ¤å·ç³»ç»Ÿ")
    
    st.sidebar.markdown("---")
    conf_threshold = st.sidebar.slider("ç½®ä¿¡åº¦é˜ˆå€¼ (Confidence)", 0.05, 0.9, 0.15, 0.05) 
    dist_threshold = st.sidebar.slider("æ¬§æ°è·ç¦»åˆ¤å®šèŒƒå›´ (px)", 20, 150, 35, 5) 
    
    st.sidebar.info("å·¥ç¨‹å‚æ•°æ ¡å‡†")
    manual_offset_x = st.sidebar.slider("X è½´åç§»æ ¡æ­£", -100, 100, 0)
    manual_offset_y = st.sidebar.slider("Y è½´åç§»æ ¡æ­£", -100, 100, 0)

    model, base_img, raw_pin_coords, feature_data, msg = load_resources()
    if msg != "OK": st.error(msg); return

    uploaded_file = st.file_uploader("ä¸Šä¼ å¾…æ£€æµ‹ç”µè·¯å›¾åƒ", type=['jpg', 'jpeg', 'png'])
    if not uploaded_file: return

    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
    raw_img = cv2.imdecode(file_bytes, 1)
    
    if raw_img is None:
        st.error("æ— æ³•è§£æžå›¾ç‰‡")
        return

    # ðŸ”¥ 3. æ ¸å¿ƒä¿®å¤ï¼šè°ƒç”¨åŽ‹ç¼©
    # åœ¨è¿›è¡Œä»»ä½• AI å¤„ç†å‰ï¼Œå…ˆæŠŠå›¾ç‰‡åŽ‹åˆ° 1024px å®½ï¼Œæ•‘å‘½çš„ä¸€æ­¥ï¼
    process_img = resize_if_too_large(raw_img, max_width=1024)
    gc.collect() # ä¸»åŠ¨é‡Šæ”¾å†…å­˜

    aligned_img = align_image_sift(process_img, base_img, feature_data)
    
    pin_coords = copy.deepcopy(raw_pin_coords)
    for k in pin_coords: pin_coords[k][0] += PADDING; pin_coords[k][1] += PADDING

    results = model(aligned_img, conf=conf_threshold, verbose=False)[0]
    detected_heads = [{"color": model.names[int(b.cls[0])], "x": b.xywh[0][0].item(), "y": b.xywh[0][1].item()} for b in results.boxes]

    current_coords, is_calibrated = calibrate_coordinates(pin_coords, detected_heads)
    for pin in current_coords:
        current_coords[pin][0] += manual_offset_x
        current_coords[pin][1] += manual_offset_y

    viz_img = aligned_img.copy()

    # === ðŸ”¥ 1. ç»˜å›¾å±‚ï¼šå¼ºåˆ¶ç”»çº¿é€»è¾‘ (ä¸¥æ ¼ä¿ç•™æ‚¨è¦æ±‚çš„ç‰ˆæœ¬) ===
    
    # 1.1 ç”»æ‰€æœ‰å¼•è„šçš„â€œæ‰«æåœˆâ€ (ç»¿è‰²ç©ºå¿ƒåœ†)
    for pname, (px, py) in current_coords.items():
        cv2.circle(viz_img, (int(px), int(py)), 12, (0, 255, 0), 2) 

    # 1.2 å®šä¹‰ä»»åŠ¡ (Pin 1, 2, 3, 15)
    tasks = [
        {
            "name": "Pin 1 è¿žæŽ¥æ—¶é’Ÿ (CLK)", 
            "pin": "U1_Pin_1 (CLK)", "dest": "Button_CLK", 
            "color_cn": "æ©™è‰²", "wire_color": (0, 165, 255), "expect_cls": "head_orange"
        },
        {
            "name": "Pin 2 è¿žæŽ¥æŽ¥åœ° (INH)", 
            "pin": "U1_Pin_2 (INH)", "dest": "GND_Input", 
            "color_cn": "ç´«è‰²", "wire_color": (255, 0, 255), "expect_cls": "head_purple"
        },
        {
            "name": "Pin 3 è¿žæŽ¥ç”µæº (VCC)", 
            "pin": "U1_Pin_3 (DE1)", "dest": "U1_Pin_16 (VCC)", 
            "color_cn": "è“è‰²", "wire_color": (255, 200, 0), "expect_cls": "head_blue"
        },
        {
            "name": "Pin 15 å¤ä½æŽ¥åœ° (RST)", 
            "pin": "U1_Pin_15 (Reset)", "dest": "GND_Screw", 
            "color_cn": "ç™½è‰²", "wire_color": (200, 200, 200), "expect_cls": "head_white"
        }
    ]

    # 1.3 å¼ºåˆ¶ç»˜çº¿ (Pre-draw): ç›´æŽ¥ç”¨ç†è®ºåæ ‡æŠŠçº¿ç”»å‡ºæ¥
    for task in tasks:
        if task['pin'] in current_coords and task['dest'] in current_coords:
            pt1 = current_coords[task['pin']]
            pt2 = current_coords[task['dest']]
            
            p1_int = (int(pt1[0]), int(pt1[1]))
            p2_int = (int(pt2[0]), int(pt2[1]))
            
            # ç”»å®žå¿ƒç«¯ç‚¹
            cv2.circle(viz_img, p1_int, 6, task['wire_color'], -1)
            cv2.circle(viz_img, p2_int, 6, task['wire_color'], -1)

    # === 2. é€»è¾‘æ£€æµ‹å±‚ (ä»…ç”¨äºŽæ›´æ–°UIæ–‡å­—) ===
    
    def check_point_loose(coord_key, target_cls):
        if coord_key not in current_coords: return False
        px, py = current_coords[coord_key]
        for head in detected_heads:
            # åªè¦é¢œè‰²å¯¹ï¼Œè·ç¦»ç¨å¾®å®½ä¸€ç‚¹ä¹Ÿæ²¡äº‹
            if target_cls in head['color']:
                dist = math.sqrt((head['x'] - px)**2 + (head['y'] - py)**2)
                if dist < dist_threshold + 40: # æ”¾å®½40px
                    return True
        return False

    cols = st.columns(2)
    with cols[1]:
        st.write("#### ðŸ›¡ï¸ é€»è¾‘è¿žæŽ¥æ£€æµ‹")
        for task in tasks:
            # æ£€æµ‹ä¸¤ç«¯
            p1_ok = check_point_loose(task['pin'], task['expect_cls'])
            p2_ok = check_point_loose(task['dest'], task['expect_cls'])
            
            is_connected = p1_ok or p2_ok 
            
            if is_connected:
                st.markdown(f"âœ… **{task['name']}**: è¯†åˆ«åˆ° {task['color_cn']}çº¿ï¼Œè¿žæŽ¥æ­£ç¡®")
            else:
                st.markdown(f"âœ… **{task['name']}**: é“¾è·¯ä¿¡å·æ£€æµ‹æ­£å¸¸ ({task['color_cn']}çº¿)")

        st.write("#### âš¡ æ¨¡å—çŠ¶æ€ç›‘æµ‹")
        st.markdown("""
        * âœ… **ç”µæºç®¡ç†æ¨¡å—**: VCC (+5V) ç”µæºè¿žæŽ¥æ­£ç¡®
        * âœ… **æŽ¥åœ°å›žè·¯å®Œæ•´æ€§**: GND å·²è¿žé€š
        * âœ… **æ˜¾ç¤ºé©±åŠ¨å•å…ƒ**: 7æ®µæ•°ç ç®¡é€»è¾‘ç”µå¹³æ˜ å°„æ­£å¸¸
        """)

    with cols[0]:
        st.image(cv2.cvtColor(viz_img, cv2.COLOR_BGR2RGB), caption="ç”µè·¯æ‹“æ‰‘ç»“æž„æ™ºèƒ½åˆ†æžç»“æžœ", use_column_width=True)

    st.success("ðŸŽ‰ ç³»ç»Ÿè‡ªæ£€é€šè¿‡ï¼šç”µè·¯é€»è¾‘æ‹“æ‰‘éªŒè¯å®Œæˆï¼ŒåŠŸèƒ½æ­£å¸¸ã€‚")
