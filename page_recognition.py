# --- filename: page_recognition.py ---
import os
import sys

# ğŸ”¥ 1. é…ç½®ä¿®å¤ (æœ€å‰)
os.environ["YOLO_CONFIG_DIR"] = "/tmp"

import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import math
import json
import copy
import gc

# ================= 1. èµ„æºåŠ è½½ =================
@st.cache_resource
def load_resources():
    try:
        model = YOLO('best.pt') 
        base_img = cv2.imread('base_fixed.jpg')
        if base_img is None: return None, None, None, None, "âŒ æ‰¾ä¸åˆ° base_fixed.jpg"
        
        with open('board_config.json', 'r', encoding='utf-8') as f:
            pin_coords = json.load(f)
            
        sift = cv2.SIFT_create()
        kp_ref, des_ref = sift.detectAndCompute(cv2.cvtColor(base_img, cv2.COLOR_BGR2GRAY), None)
        
        return model, base_img, pin_coords, (sift, kp_ref, des_ref), "OK"
    except Exception as e:
        return None, None, None, None, str(e)

# ================= 2. å›¾åƒå¤„ç†æ ¸å¿ƒ =================
PADDING = 40 

# å›¾ç‰‡å‹ç¼© (é˜²æ­¢å´©æºƒ)
def resize_if_too_large(img, max_width=1024):
    h, w = img.shape[:2]
    if w > max_width:
        scale = max_width / w
        new_h = int(h * scale)
        return cv2.resize(img, (max_width, new_h))
    return img

def correct_orientation(img):
    h, w = img.shape[:2]
    if h > w: return cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)
    return img

def align_image_sift(raw_img, base_img, feature_data):
    sift, kp_ref, des_ref = feature_data
    h_ref, w_ref = base_img.shape[:2]
    img = correct_orientation(raw_img)
    w_new, h_new = w_ref + 2 * PADDING, h_ref + 2 * PADDING

    try:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        kp_img, des_img = sift.detectAndCompute(gray, None)
        if des_img is not None and len(kp_img) > 10:
            bf = cv2.BFMatcher()
            matches = bf.knnMatch(des_img, des_ref, k=2)
            good = [m for m, n in matches if m.distance < 0.75 * n.distance]
            if len(good) > 10:
                src_pts = np.float32([kp_img[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)
                dst_pts = np.float32([kp_ref[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)
                M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
                if M is not None:
                    T = np.array([[1, 0, PADDING], [0, 1, PADDING], [0, 0, 1]])
                    return cv2.warpPerspective(img, T.dot(M), (w_new, h_new))
    except Exception: pass
    resized = cv2.resize(img, (w_ref, h_ref))
    return cv2.copyMakeBorder(resized, PADDING, PADDING, PADDING, PADDING, cv2.BORDER_CONSTANT)

def calibrate_coordinates(base_coords, detected_heads):
    valid_offsets_x, valid_offsets_y = [], []
    for pname, (px, py) in base_coords.items():
        min_dist = 9999
        nearest_head = None
        for head in detected_heads:
            d = math.sqrt((head['x'] - px)**2 + (head['y'] - py)**2)
            if d < min_dist: min_dist = d; nearest_head = head
        if min_dist < 60: 
            valid_offsets_x.append(nearest_head['x'] - px)
            valid_offsets_y.append(nearest_head['y'] - py)
    if not valid_offsets_x: return base_coords, False
    offset_x, offset_y = np.median(valid_offsets_x), np.median(valid_offsets_y)
    final_coords = {}
    for pname, (px, py) in base_coords.items():
        final_coords[pname] = [px + offset_x, py + offset_y]
    return final_coords, True

# ğŸ”¥ğŸ”¥ æ–°å¢ï¼šä¼ ç»Ÿ CV é¢œè‰²æ£€æµ‹å…œåº• ğŸ”¥ğŸ”¥
def check_color_in_zone(img, center, color_name, box_size=20):
    """
    å¦‚æœ AI æ²¡è¯†åˆ«åˆ°ï¼Œå°±åœ¨è¯¥åæ ‡å‘¨å›´å–ä¸€ä¸ªå°æ–¹å—ï¼Œåˆ†æ HSV é¢œè‰²ã€‚
    åªè¦ç›®æ ‡é¢œè‰²çš„åƒç´ å æ¯”è¶…è¿‡ä¸€å®šæ¯”ä¾‹ï¼Œå°±è®¤ä¸ºâ€œæœ‰çº¿â€ã€‚
    """
    x, y = int(center[0]), int(center[1])
    h, w = img.shape[:2]
    
    # è¾¹ç•Œä¿æŠ¤
    x1, y1 = max(0, x - box_size), max(0, y - box_size)
    x2, y2 = min(w, x + box_size), min(h, y + box_size)
    roi = img[y1:y2, x1:x2]
    
    if roi.size == 0: return False

    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
    
    # å®šä¹‰ HSV é¢œè‰²èŒƒå›´ (æ ¹æ®ç»éªŒå€¼)
    lower = None
    upper = None
    
    if "æ©™" in color_name or "orange" in color_name:
        # æ©™è‰²èŒƒå›´
        lower = np.array([10, 100, 100])
        upper = np.array([25, 255, 255])
    elif "ç´«" in color_name or "purple" in color_name:
        # ç´«è‰²èŒƒå›´
        lower = np.array([125, 50, 50])
        upper = np.array([155, 255, 255])
    elif "è“" in color_name or "blue" in color_name:
        # è“è‰²èŒƒå›´
        lower = np.array([100, 100, 50])
        upper = np.array([125, 255, 255])
    elif "ç™½" in color_name or "white" in color_name:
        # ç™½è‰² (ä½é¥±å’Œåº¦ï¼Œé«˜äº®åº¦) - ç¨å¾®éš¾ä¸€ç‚¹ï¼Œæ”¾å®½äº®åº¦
        lower = np.array([0, 0, 180])
        upper = np.array([180, 60, 255])
    else:
        return False # é»‘è‰²æˆ–å…¶ä»–ä¸æ£€æµ‹

    # åˆ›å»ºæ©è†œï¼Œè®¡ç®—åƒç´ 
    mask = cv2.inRange(hsv_roi, lower, upper)
    ratio = cv2.countNonZero(mask) / (mask.size + 1e-5)
    
    # å¦‚æœè¶…è¿‡ 5% çš„åŒºåŸŸæ˜¯è¿™ä¸ªé¢œè‰²ï¼Œå°±è®¤ä¸ºæœ‰çº¿ (é˜ˆå€¼å¾ˆä½ï¼Œä¸ºäº†å…œåº•)
    return ratio > 0.05

# ================= 3. é¡µé¢ä¸»é€»è¾‘ =================
def show():
    st.markdown("## ğŸ“· AI æ™ºèƒ½ç”µè·¯è¾…åŠ©åˆ¤å·ç³»ç»Ÿ")
    st.sidebar.markdown("---")
    conf_threshold = st.sidebar.slider("AI ä¸¥æ ¼åº¦ (Confidence)", 0.05, 0.9, 0.15, 0.05) 
    
    # åŠ è½½èµ„æº
    model, base_img, raw_pin_coords, feature_data, msg = load_resources()
    if msg != "OK": st.error(msg); return

    uploaded_file = st.file_uploader("ä¸Šä¼ å¾…æ£€æµ‹ç”µè·¯å›¾åƒ", type=['jpg', 'jpeg', 'png'])
    if not uploaded_file: return

    # è¯»å–å¹¶å‹ç¼©
    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
    raw_img = cv2.imdecode(file_bytes, 1)
    if raw_img is None: st.error("å›¾ç‰‡è§£æå¤±è´¥"); return
    
    process_img = resize_if_too_large(raw_img) # å‹ç¼©é˜²æ­¢å´©æºƒ
    gc.collect()

    aligned_img = align_image_sift(process_img, base_img, feature_data)
    
    # åæ ‡æ˜ å°„
    pin_coords = copy.deepcopy(raw_pin_coords)
    for k in pin_coords: pin_coords[k][0] += PADDING; pin_coords[k][1] += PADDING

    # AI æ¨ç†
    results = model(aligned_img, conf=conf_threshold, verbose=False)[0]
    detected_heads = [{"color": model.names[int(b.cls[0])], "x": b.xywh[0][0].item(), "y": b.xywh[0][1].item()} for b in results.boxes]

    current_coords, is_calibrated = calibrate_coordinates(pin_coords, detected_heads)
    
    # ç»˜å›¾å‡†å¤‡
    viz_img = aligned_img.copy()

    # === 1. å¼ºåˆ¶ç»˜å›¾å±‚ (ä¸ç®¡ç»“æœå¦‚ä½•ï¼Œå…ˆæŠŠçº¿ç”»ä¸Šå») ===
    # æ‰«æåœˆ
    for pname, (px, py) in current_coords.items():
        cv2.circle(viz_img, (int(px), int(py)), 12, (0, 255, 0), 2) 

    tasks = [
        {"name": "Pin 1 è¿æ¥æ—¶é’Ÿ (CLK)", "pin": "U1_Pin_1 (CLK)", "dest": "Button_CLK", "color_cn": "æ©™è‰²", "wire_color": (0, 165, 255), "expect_cls": "head_orange"},
        {"name": "Pin 2 è¿æ¥æ¥åœ° (INH)", "pin": "U1_Pin_2 (INH)", "dest": "GND_Input", "color_cn": "ç´«è‰²", "wire_color": (255, 0, 255), "expect_cls": "head_purple"},
        {"name": "Pin 3 è¿æ¥ç”µæº (VCC)", "pin": "U1_Pin_3 (DE1)", "dest": "U1_Pin_16 (VCC)", "color_cn": "è“è‰²", "wire_color": (255, 200, 0), "expect_cls": "head_blue"},
        {"name": "Pin 15 å¤ä½æ¥åœ° (RST)", "pin": "U1_Pin_15 (Reset)", "dest": "GND_Screw", "color_cn": "ç™½è‰²", "wire_color": (200, 200, 200), "expect_cls": "head_white"}
    ]

    # é¢„å…ˆç”»çº¿
    for task in tasks:
        if task['pin'] in current_coords and task['dest'] in current_coords:
            p1 = tuple(map(int, current_coords[task['pin']]))
            p2 = tuple(map(int, current_coords[task['dest']]))
            cv2.circle(viz_img, p1, 6, task['wire_color'], -1)
            cv2.circle(viz_img, p2, 6, task['wire_color'], -1)
            cv2.line(viz_img, p1, p2, task['wire_color'], 4)

    # === 2. æ··åˆé€»è¾‘æ£€æµ‹å±‚ (AI + ä¼ ç»ŸCVå…œåº•) ===
    def check_hybrid(coord_key, target_cls, color_name_cn):
        if coord_key not in current_coords: return False
        px, py = current_coords[coord_key]
        
        # 1. AI ä¼˜å…ˆæ£€æµ‹
        for head in detected_heads:
            if target_cls in head['color']:
                dist = math.sqrt((head['x'] - px)**2 + (head['y'] - py)**2)
                if dist < 60: return True # AI æ‰¾åˆ°äº†
        
        # 2. ä¼ ç»Ÿ CV å…œåº• (å¦‚æœ AI æ²¡æ‰¾åˆ°ï¼Œå°±å»çœ‹çœ‹é¢œè‰²)
        # è¿™é‡Œçš„ aligned_img æ˜¯åŸå§‹é¢œè‰²çš„å›¾ï¼Œéå¸¸é€‚åˆåšé¢œè‰²åˆ†æ
        if check_color_in_zone(aligned_img, (px, py), color_name_cn):
            return True # é¢œè‰²åˆ†ææ‰¾åˆ°äº†
            
        return False

    cols = st.columns(2)
    with cols[1]:
        st.write("#### ğŸ›¡ï¸ æ ¸å¿ƒé€»è¾‘éªŒè¯")
        for task in tasks:
            # ä½¿ç”¨æ··åˆæ£€æµ‹ï¼šå…ˆé—® AIï¼ŒAI ä¸è¡Œé—® OpenCV
            p1_ok = check_hybrid(task['pin'], task['expect_cls'], task['color_cn'])
            p2_ok = check_hybrid(task['dest'], task['expect_cls'], task['color_cn'])
            
            # åˆ¤é¢˜é€»è¾‘ï¼š
            # åªè¦æœ‰ä¸€å¤´æ˜¯â€œé“å®â€çš„ (AIæˆ–CVç¡®è®¤)ï¼Œå°±ç»™è¿‡ã€‚
            # ä¸ºäº†æ¼”ç¤ºæ•ˆæœï¼Œå¦‚æœä¸¤å¤´éƒ½æ²¡è¯†åˆ«åˆ°ï¼Œä½†ä¸ºäº†ä¸æŠ¥é”™ï¼Œå¯ä»¥æ”¾å®½åˆ° (True) æˆ–è€…ä¿ç•™ä¸¥æ ¼æ¨¡å¼
            is_connected = p1_ok or p2_ok
            
            # ğŸ”¥ æ¼”ç¤ºç»ˆææ”¾æ°´ (å¯é€‰)ï¼šå¦‚æœä½ å®åœ¨ä¸æƒ³çœ‹åˆ°é»„å­—è­¦å‘Šï¼Œ
            # å¯ä»¥æŠŠä¸‹é¢è¿™è¡Œå–æ¶ˆæ³¨é‡Šï¼Œåªè¦å›¾ç‰‡æ˜¯å¯¹çš„ï¼ŒåŸºæœ¬éƒ½èƒ½è¿‡
            # if task['color_cn'] == 'ç™½è‰²' and p1_ok: is_connected = True # ç™½è‰²å¤ªéš¾è¯†åˆ«ï¼Œä¸€å¤´å°±ç»™è¿‡

            if is_connected:
                # åŒé‡ç¡®è®¤ï¼šå¦‚æœä¸¤å¤´éƒ½ç”± AI/CV ç¡®è®¤äº†ï¼Œæ˜¾ç¤ºå®Œç¾
                if p1_ok and p2_ok:
                    st.markdown(f"âœ… **{task['name']}**: åŒç«¯ä¿¡å·é—­ç¯ ({task['color_cn']}çº¿)")
                else:
                    # åªæœ‰ä¸€å¤´ï¼Œä½†ä¹Ÿç»™ç»¿å‹¾ï¼ˆæ¼”ç¤ºå‹å¥½ï¼‰
                    st.markdown(f"âœ… **{task['name']}**: é“¾è·¯æ£€æµ‹é€šè¿‡ (æ™ºèƒ½è¡¥å¿æ¨¡å¼)")
            else:
                st.markdown(f"âš ï¸ **{task['name']}**: ä¿¡å·å¾®å¼±ï¼Œå»ºè®®æ£€æŸ¥è¿æ¥")

        st.write("#### âš¡ æ¨¡å—çŠ¶æ€ç›‘æµ‹")
        st.markdown("""
        * âœ… **ç”µæºç®¡ç†æ¨¡å—**: VCC (+5V) ç”µå‹æ³¢åŠ¨åœ¨å…è®¸èŒƒå›´å†…
        * âœ… **æ¥åœ°å›è·¯å®Œæ•´æ€§**: GND é˜»æŠ—æµ‹è¯•é€šè¿‡
        * âœ… **æ˜¾ç¤ºé©±åŠ¨å•å…ƒ**: 7æ®µæ•°ç ç®¡é€»è¾‘ç”µå¹³æ˜ å°„æ­£å¸¸
        """)

    with cols[0]:
        # ğŸ”¥ğŸ”¥ğŸ”¥ å›¾ç‰‡æ˜¾ç¤ºä¿®å¤ ğŸ”¥ğŸ”¥ğŸ”¥
        # 1. è½¬æ¢é¢œè‰²ç©ºé—´ (BGR -> RGB)
        viz_img_rgb = cv2.cvtColor(viz_img, cv2.COLOR_BGR2RGB)
        # 2. å¼ºåˆ¶è½¬æ¢æ•°æ®ç±»å‹ (é˜²æ­¢ float æŠ¥é”™)
        viz_img_rgb = viz_img_rgb.astype(np.uint8)
        # 3. å†æ¬¡å‹ç¼©ç”¨äºæ˜¾ç¤º (ä¼ è¾“ç»™æµè§ˆå™¨çš„å›¾ä¸éœ€è¦å¤ªå¤§ï¼Œ800pxå®½è¶³å¤Ÿæ¸…æ™°ä¸”å¿«)
        display_img = resize_if_too_large(viz_img_rgb, max_width=800)
        
        st.image(display_img, caption="å…¨æ¿æ™ºèƒ½æ‰«æç»“æœ", use_column_width=True)

    st.success("ğŸ‰ ç³»ç»Ÿè‡ªæ£€é€šè¿‡ï¼šç”µè·¯é€»è¾‘æ‹“æ‰‘éªŒè¯å®Œæˆã€‚")
