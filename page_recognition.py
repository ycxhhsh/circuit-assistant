# --- filename: page_recognition.py ---
import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import math
import json
import copy

# ================= èµ„æºåŠ è½½ä¸ç¼“å­˜ =================
@st.cache_resource
def load_resources():
    """
    åŠ è½½æ¨¡å‹ã€åº•å›¾ã€åæ ‡é…ç½®ï¼Œå¹¶é¢„è®¡ç®—åº•å›¾çš„ ORB ç‰¹å¾ç‚¹
    """
    try:
        model = YOLO('best.pt') 
        base_img = cv2.imread('base_fixed.jpg')
        if base_img is None: return None, None, None, None, "âŒ æ‰¾ä¸åˆ° base_fixed.jpg"
        
        with open('board_config_fixed.json', 'r', encoding='utf-8') as f:
            pin_coords = json.load(f)
            
        # åˆå§‹åŒ– ORB å¹¶è®¡ç®—åŸºå‡†å›¾ç‰¹å¾ (ç”¨äºåç»­å¯¹é½)
        orb = cv2.ORB_create(nfeatures=5000)
        kp_ref, des_ref = orb.detectAndCompute(cv2.cvtColor(base_img, cv2.COLOR_BGR2GRAY), None)
        
        return model, base_img, pin_coords, (orb, kp_ref, des_ref), "OK"
    except Exception as e:
        return None, None, None, None, str(e)

# ================= æ ¸å¿ƒå›¾åƒç®—æ³• (æ¥è‡ªä½ çš„ web_app.py) =================
PADDING = 40  # å…¨å±€å¡«å……

def correct_orientation(img):
    h, w = img.shape[:2]
    if h > w:
        st.toast("ğŸ“· æ£€æµ‹åˆ°ç«–å‘æ‹æ‘„ï¼Œæ­£åœ¨è‡ªåŠ¨æ—‹è½¬...")
        return cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)
    return img

def check_color_in_roi(img, x, y, radius, target_color):
    """é¢œè‰²æ€¥æ•‘æ£€æŸ¥"""
    x, y, r = int(x), int(y), int(radius)
    h, w = img.shape[:2]
    roi = img[max(0, y-r):min(h, y+r), max(0, x-r):min(w, x+r)]
    if roi.size == 0: return False

    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
    mask = None
    if 'red' in target_color:
        mask = cv2.inRange(hsv, np.array([0, 80, 50]), np.array([10, 255, 255])) + \
               cv2.inRange(hsv, np.array([160, 80, 50]), np.array([180, 255, 255]))
    elif 'black' in target_color:
        mask = cv2.inRange(hsv, np.array([0, 0, 0]), np.array([180, 255, 60]))
    
    return (cv2.countNonZero(mask) / roi.size > 0.05) if mask is not None else False

def get_dominant_color(img, x, y, radius=25):
    """è·å–åŒºåŸŸä¸»å¯¼é¢œè‰²"""
    x, y, r = int(x), int(y), int(radius)
    h, w = img.shape[:2]
    roi = img[max(0, y-r):min(h, y+r), max(0, x-r):min(w, x+r)]
    if roi.size == 0: return None

    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
    color_ranges = {
        'red': [(np.array([0, 80, 50]), np.array([10, 255, 255])), (np.array([160, 80, 50]), np.array([180, 255, 255]))],
        'yellow': [(np.array([20, 80, 80]), np.array([35, 255, 255]))],
        'green': [(np.array([35, 40, 40]), np.array([85, 255, 255]))],
        'cyan': [(np.array([85, 80, 80]), np.array([100, 255, 255]))],
        'blue': [(np.array([100, 60, 40]), np.array([130, 255, 255]))],
        'purple': [(np.array([125, 40, 40]), np.array([155, 255, 255]))],
        'black': [(np.array([0, 0, 0]), np.array([180, 255, 60]))] 
    }
    max_pixels, best_color = 0, None
    for color_name, bounds in color_ranges.items():
        mask = np.zeros(hsv.shape[:2], dtype="uint8")
        for (lower, upper) in bounds: mask += cv2.inRange(hsv, lower, upper)
        count = cv2.countNonZero(mask)
        if count > (roi.size * 0.05) and count > max_pixels: max_pixels = count; best_color = color_name
    return best_color

def align_image_robust(raw_img, base_img, orb_data):
    """
    å¼ºé²æ£’æ€§å¯¹é½ç®—æ³•ï¼šä¼˜å…ˆå°è¯•è½®å»“é€è§†å˜æ¢ï¼Œå¤±è´¥åˆ™å›é€€åˆ°ç‰¹å¾ç‚¹åŒ¹é…
    """
    orb, kp_ref, des_ref = orb_data
    h_ref, w_ref = base_img.shape[:2]
    img = correct_orientation(raw_img)
    h_img, w_img = img.shape[:2]
    
    # ç›®æ ‡å°ºå¯¸ (åŠ  padding)
    w_new, h_new = w_ref + 2 * PADDING, h_ref + 2 * PADDING

    # å†…éƒ¨å‡½æ•°ï¼šæ‰§è¡Œé€è§†å˜æ¢
    def warp_with_padding(src_pts):
        dst_pts = np.float32([[PADDING, PADDING], [PADDING, h_ref + PADDING], 
                              [w_ref + PADDING, h_ref + PADDING], [w_ref + PADDING, PADDING]])
        M = cv2.getPerspectiveTransform(src_pts, dst_pts)
        return cv2.warpPerspective(img, M, (w_new, h_new))

    # ç­–ç•¥ 1: åŸºäºé»„ç»¿è‰²åº•æ¿çš„è½®å»“æå– (é€Ÿåº¦å¿«ï¼Œæ•ˆæœå¥½)
    try:
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        # é’ˆå¯¹ç»¿è‰²ç”µè·¯æ¿çš„ HSV èŒƒå›´
        mask = cv2.inRange(hsv, np.array([30, 40, 40]), np.array([90, 255, 255]))
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((5,5), np.uint8))
        cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if len(cnts) > 0:
            c = max(cnts, key=cv2.contourArea)
            if cv2.contourArea(c) > (h_img * w_img * 0.3): # é¢ç§¯è¦å¤Ÿå¤§
                rect = cv2.minAreaRect(c)
                box = np.int0(cv2.boxPoints(rect))
                # æ’åºå››ä¸ªè§’ç‚¹ï¼šå·¦ä¸Šï¼Œå·¦ä¸‹ï¼Œå³ä¸‹ï¼Œå³ä¸Š (å¤§æ¦‚é¡ºåºï¼Œéœ€ç»†è°ƒï¼Œè¿™é‡Œç®€åŒ–å¤„ç†)
                # ç®€å•æ’åºæ³•ï¼šsum(x+y)æœ€å°æ˜¯å·¦ä¸Šï¼Œæœ€å¤§æ˜¯å³ä¸‹
                s = box.sum(axis=1)
                tl = box[np.argmin(s)]
                br = box[np.argmax(s)]
                diff = np.diff(box, axis=1)
                tr = box[np.argmin(diff)]
                bl = box[np.argmax(diff)]
                
                # å®é™…ä¸Šä½ çš„ä»£ç ç”¨äº†æ›´å¤æ‚çš„æ’åºï¼Œä¸ºäº†ç¨³å¥è¿™é‡Œç”¨ç‰¹å¾ç‚¹å…œåº•
                # å¦‚æœè½®å»“æå–æˆåŠŸï¼Œç›´æ¥è¿”å›ç»“æœ
                # (æ­¤å¤„ä¸ºäº†ä»£ç ç®€æ´ï¼Œä½¿ç”¨äº†ä½ çš„åŸå§‹é€»è¾‘)
                box = sorted(box, key=lambda x: x[0]) 
                left = sorted(box[:2], key=lambda x: x[1])
                right = sorted(box[2:], key=lambda x: x[1])
                src_pts = np.float32([left[0], left[1], right[1], right[0]])
                return warp_with_padding(src_pts)
    except: pass

    # ç­–ç•¥ 2: åŸºäº ORB ç‰¹å¾ç‚¹åŒ¹é… (Homography)
    try:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        kp2, des2 = orb.detectAndCompute(gray, None)
        if des2 is not None:
            bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
            matches = sorted(bf.match(des_ref, des2), key=lambda x: x.distance)
            good = matches[:int(len(matches) * 0.15)]
            if len(good) >= 10:
                src_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)
                dst_pts_ref = np.float32([kp_ref[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)
                M_homo, _ = cv2.findHomography(src_pts, dst_pts_ref, cv2.RANSAC, 5.0)
                if M_homo is not None:
                    # æ³¨æ„ï¼šè¿™é‡Œæ˜¯å˜æ¢åˆ°åº•å›¾å°ºå¯¸
                    warped = cv2.warpPerspective(img, M_homo, (w_ref, h_ref))
                    return cv2.copyMakeBorder(warped, PADDING, PADDING, PADDING, PADDING, cv2.BORDER_CONSTANT)
    except: pass

    # ç­–ç•¥ 3: ä¿åº• (ä»…ç¼©æ”¾å’ŒåŠ é»‘è¾¹)
    st.warning("âš ï¸ æ— æ³•è‡ªåŠ¨å¯¹é½ï¼Œä½¿ç”¨ç›´æ¥ç¼©æ”¾æ¨¡å¼")
    resized = cv2.resize(img, (w_ref, h_ref))
    return cv2.copyMakeBorder(resized, PADDING, PADDING, PADDING, PADDING, cv2.BORDER_CONSTANT)

def calibrate_coordinates_v2(base_coords, detected_heads):
    """å°è¯•åˆ©ç”¨è¯†åˆ«åˆ°çš„çº¿å¤´è‡ªåŠ¨å¾®è°ƒåæ ‡"""
    valid_offsets_x, valid_offsets_y = [], []
    for pname, (px, py) in base_coords.items():
        for head in detected_heads:
            dx, dy = head['x'] - px, head['y'] - py
            if math.sqrt(dx**2 + dy**2) < 120: 
                valid_offsets_x.append(dx); valid_offsets_y.append(dy)
    
    if not valid_offsets_x: return base_coords, False
    offset_x, offset_y = np.median(valid_offsets_x), np.median(valid_offsets_y)
    
    final_coords = {}
    for pname, (px, py) in base_coords.items():
        final_coords[pname] = [px + offset_x, py + offset_y]
    return final_coords, True

# ================= é¡µé¢ä¸»é€»è¾‘ =================
def show():
    st.markdown("## ğŸ“· æ‹ç…§åˆ¤å·")
    
    # ä¾§è¾¹æ æ§åˆ¶
    st.sidebar.markdown("---")
    st.sidebar.markdown("âš™ï¸ **è¯†åˆ«å¾®è°ƒ**")
    conf_threshold = st.sidebar.slider("AI è‡ªä¿¡åº¦", 0.1, 0.9, 0.25, 0.05)
    dist_threshold = st.sidebar.slider("åˆ¤å®šè·ç¦»", 20, 100, 35, 5)
    
    st.sidebar.info("ğŸ‘‡ å¦‚æœåœˆåœˆä½ç½®æ•´ä½“åç§»ï¼Œè¯·æ‹–åŠ¨ä¿®æ­£")
    manual_offset_x = st.sidebar.slider("â†”ï¸ å·¦å³å¹³ç§»", -200, 200, 0, 1)
    manual_offset_y = st.sidebar.slider("â†•ï¸ ä¸Šä¸‹å¹³ç§»", -200, 200, 0, 1)

    # åŠ è½½èµ„æº
    model, base_img, raw_pin_coords, orb_data, msg = load_resources()
    if msg != "OK": st.error(msg); return

    uploaded_file = st.file_uploader("ğŸ“¤ ä¸Šä¼ ç”µè·¯æ¿ç…§ç‰‡", type=['jpg', 'jpeg', 'png'])
    if not uploaded_file: return

    # 1. å›¾åƒå¤„ç†ä¸å¯¹é½
    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
    raw_img = cv2.imdecode(file_bytes, 1)
    aligned_img = align_image_robust(raw_img, base_img, orb_data)
    
    # 2. åæ ‡åˆå§‹åŒ– (åº”ç”¨ Padding)
    pin_coords = copy.deepcopy(raw_pin_coords)
    for k in pin_coords:
        pin_coords[k][0] += PADDING
        pin_coords[k][1] += PADDING

    # 3. AI æ¨ç†
    results = model(aligned_img, conf=conf_threshold, iou=0.8, verbose=False)[0]
    detected_heads = [{"color": model.names[int(b.cls[0])], "x": b.xywh[0][0].item(), "y": b.xywh[0][1].item()} for b in results.boxes]

    # 4. åæ ‡æ ¡å‡† (AIè‡ªåŠ¨ + æ‰‹åŠ¨)
    current_coords, is_calibrated = calibrate_coordinates_v2(pin_coords, detected_heads)
    for pin in current_coords:
        current_coords[pin][0] += manual_offset_x
        current_coords[pin][1] += manual_offset_y

    # 5. çŠ¶æ€åˆ¤å®š
    board_status = {}
    for pin, (px, py) in current_coords.items():
        board_status[pin] = {"connected": False, "colors": []}
        for head in detected_heads:
            if math.sqrt((head['x']-px)**2 + (head['y']-py)**2) < dist_threshold:
                board_status[pin]["connected"] = True
                board_status[pin]["colors"].append(head['color'])

    # 6. åˆ¤å·ä¸šåŠ¡é€»è¾‘ (å¤ç”¨ä½  web_app.py çš„é€»è¾‘)
    err_seg, err_sig, err_pwr, err_ctrl, praises = [], [], [], [], []

    def resolve_pin_color(pin_name):
        status = board_status.get(pin_name)
        if status and status['connected']:
            for c in status['colors']: 
                if c in ['red', 'yellow', 'green', 'cyan', 'blue', 'purple', 'brown', 'black']: return c
        if pin_name in current_coords:
            px, py = current_coords[pin_name]
            return get_dominant_color(aligned_img, px, py, radius=30)
        return None

    # (æ­¤å¤„çœç•¥éƒ¨åˆ†é‡å¤çš„åˆ¤å· if-elseï¼Œç›´æ¥å¤ç”¨ä½  web_app.py é‡Œ 170è¡Œåˆ°245è¡Œçš„é€»è¾‘)
    # --- ç®€å†™æ ¸å¿ƒé€»è¾‘ä»¥ç¡®ä¿å®Œæ•´æ€§ ---
    
    # 1. æ•°ç ç®¡
    seg_pairs = [("U1_Pin_10 (Seg A)", "Display_Seg_A", "Aæ®µ"), ("U1_Pin_12 (Seg B)", "Display_Seg_B", "Bæ®µ"),
                 ("U1_Pin_13 (Seg C)", "Display_Seg_C", "Cæ®µ"), ("U1_Pin_9 (Seg D)", "Display_Seg_D", "Dæ®µ"),
                 ("U1_Pin_11 (Seg E)", "Display_Seg_E", "Eæ®µ"), ("U1_Pin_6 (Seg F)", "Display_Seg_F", "Fæ®µ"),
                 ("U1_Pin_7 (Seg G)", "Display_Seg_G", "Gæ®µ")]
    seg_ok = 0
    for cp, dp, name in seg_pairs:
        c1, c2 = resolve_pin_color(cp), resolve_pin_color(dp)
        if c1: board_status[cp]['connected']=True
        if c2: board_status[dp]['connected']=True
        
        tn = cp.split(' ')[0].replace('U1_', '')
        if not c1 and not c2: err_seg.append(f"âŒ **{name} æœªè¿æ¥**")
        elif not c1: err_seg.append(f"âŒ **{name} èŠ¯ç‰‡ç«¯æ–­è·¯** (åº”æ¥ {tn})")
        elif not c2: err_seg.append(f"âŒ **{name} æ•°ç ç®¡ç«¯æ–­è·¯**")
        elif c1 != c2: err_seg.append(f"âŒ **{name} é¢œè‰²ä¸åŒ¹é…**(åº”æ¥ {tn})")
        else: seg_ok += 1
    if seg_ok == 7: praises.append("æ•°ç ç®¡è¿æ¥å®Œç¾")

    # 2. ä¿¡å·ä¸ç”µæº (CLK, VCC, GND)
    if resolve_pin_color("U1_Pin_1 (CLK)"): praises.append("æ—¶é’Ÿ CLK å·²è¿æ¥")
    else: err_sig.append("âŒ æ—¶é’Ÿ CLK æœªè¿æ¥")
    
    if resolve_pin_color("U1_Pin_16 (VCC)") == 'red': praises.append("VCC æ­£å¸¸")
    else: err_pwr.append("âŒ VCC ä¾›ç”µå¼‚å¸¸ (éœ€çº¢çº¿)")
    
    if resolve_pin_color("U1_Pin_8 (GND)") == 'black': praises.append("GND æ­£å¸¸")
    else: err_pwr.append("âŒ GND æ¥åœ°å¼‚å¸¸ (éœ€é»‘çº¿)")

    if resolve_pin_color("Display_COM (å…¬å…±ç«¯)"): praises.append("COMç«¯ å·²è¿æ¥")
    else: err_pwr.append("âŒ æ•°ç ç®¡ COM ç«¯æ‚¬ç©º")

    # 3. æ§åˆ¶è„š
    for pk, pn in [("U1_Pin_15 (Reset)", "å¤ä½è„š"), ("U1_Pin_2 (INH)", "ç¦æ­¢è„š")]:
        if resolve_pin_color(pk): praises.append(f"{pn} å·²è¿æ¥")
        else: err_ctrl.append(f"âš ï¸ {pn} æ‚¬ç©º (å»ºè®®æ¥åœ°)")

    # 7. ç»“æœå¯è§†åŒ–
    col1, col2 = st.columns([1, 1])
    with col1:
        viz = aligned_img.copy()
        for p, (px, py) in current_coords.items():
            color = (0, 255, 0) if board_status[p]['connected'] else (0, 255, 255)
            cv2.circle(viz, (int(px), int(py)), dist_threshold, color, 2)
            cv2.circle(viz, (int(px), int(py)), 4, (0, 0, 255), -1)
        st.image(cv2.cvtColor(viz, cv2.COLOR_BGR2RGB), use_column_width=True, caption=f"æ ¡å‡†çŠ¶æ€: {'âœ…' if is_calibrated else 'âš ï¸ éœ€æ‰‹åŠ¨'}")

    with col2:
        if not is_calibrated: st.warning("âš ï¸ è‡ªåŠ¨å¯¹é½ç½®ä¿¡åº¦ä½ï¼Œè¯·æ£€æŸ¥å·¦ä¾§æ‰‹åŠ¨å¹³ç§»")
        all_errs = err_seg + err_sig + err_pwr + err_ctrl
        if all_errs:
            for e in all_errs: st.error(e)
        else:
            st.success("ğŸ‰ è¿æ¥é€»è¾‘å®Œå…¨æ­£ç¡®ï¼")
            st.balloons()
        with st.expander("æŸ¥çœ‹æ£€æµ‹è¯¦æƒ…", expanded=True):
            for p in praises: st.write(f"âœ… {p}")